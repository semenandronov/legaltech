"""
Chat Tools - –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è ReAct Chat Agent

–ù–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∞–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç –°–ê–ú –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–æ–ø—Ä–æ—Å–∞:
- search_documents: –ø–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º (k=5-100)
- list_case_files: —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–µ–ª–µ
- get_file_summary: –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
- summarize_all_documents: Map-Reduce —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- extract_entities: –∏–∑–≤–ª–µ—á—å —Å—É—â–Ω–æ—Å—Ç–∏ (–¥–∞—Ç—ã, –∏–º–µ–Ω–∞, —Å—É–º–º—ã)
- find_contradictions: –Ω–∞–π—Ç–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
- analyze_risks: –∞–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤
- build_timeline: –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é
- search_garant: –ø–æ–∏—Å–∫ –≤ GARANT (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- search_web: –≤–µ–±-–ø–æ–∏—Å–∫ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
"""
from typing import List, Dict, Any, Optional
from langchain_core.tools import tool
from sqlalchemy.orm import Session
import asyncio
import logging

logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–∏–Ω–∂–µ–∫—Ç–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ tools)
_db: Optional[Session] = None
_rag_service = None
_case_id: Optional[str] = None


def initialize_chat_tools(db: Session, rag_service, case_id: str):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è tools"""
    global _db, _rag_service, _case_id
    _db = db
    _rag_service = rag_service
    _case_id = case_id


# =============================================================================
# –û—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø–æ–∏—Å–∫–∞
# =============================================================================

@tool
def search_documents(query: str, k: int = 10) -> str:
    """
    –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –¥–µ–ª–∞.
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞:
    - –ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    - –ù—É–∂–Ω—ã —Ñ–∞–∫—Ç—ã, –¥–∞—Ç—ã, —Å—É–º–º—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ (5-100, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
           –ò—Å–ø–æ–ª—å–∑—É–π k=5 –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
           –ò—Å–ø–æ–ª—å–∑—É–π k=20-50 –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
           –ò—Å–ø–æ–ª—å–∑—É–π k=100 –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    
    Returns:
        –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
    """
    global _rag_service, _case_id, _db
    
    if not _rag_service or not _case_id:
        return "–û—à–∏–±–∫–∞: —Å–µ—Ä–≤–∏—Å –ø–æ–∏—Å–∫–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
    
    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º k —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
        k = max(5, min(100, k))
        
        documents = _rag_service.retrieve_context(
            case_id=_case_id,
            query=query,
            k=k,
            retrieval_strategy="multi_query",
            db=_db
        )
        
        if not documents:
            return f"–ü–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        formatted = _rag_service.format_sources_for_prompt(documents, max_context_chars=8000)
        logger.info(f"[ChatTools] search_documents: –Ω–∞–π–¥–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è '{query[:50]}...'")
        
        return formatted
        
    except Exception as e:
        logger.error(f"[ChatTools] search_documents error: {e}")
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}"


@tool
def list_case_files() -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–µ–ª–µ.
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞:
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç "–∫–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –¥–µ–ª–µ?"
    - –ù—É–∂–Ω–æ —É–∑–Ω–∞—Ç—å, —á—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ –¥–µ–ª–æ
    - –ü–µ—Ä–µ–¥ –æ–±–∑–æ—Ä–æ–º –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Å –∏—Ö —Ç–∏–ø–∞–º–∏ –∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏
    """
    global _db, _case_id
    
    if not _db or not _case_id:
        return "–û—à–∏–±–∫–∞: –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"
    
    try:
        from app.models.case import File as FileModel
        
        files = _db.query(FileModel).filter(
            FileModel.case_id == _case_id
        ).all()
        
        if not files:
            return "–í –¥–µ–ª–µ –Ω–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        result_lines = [f"üìÅ **–í –¥–µ–ª–µ {len(files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**\n"]
        
        for i, f in enumerate(files, 1):
            file_type = f.doc_type or "unknown"
            file_size = f.file_size or 0
            size_str = f"{file_size / 1024:.1f} KB" if file_size < 1024*1024 else f"{file_size / (1024*1024):.1f} MB"
            
            result_lines.append(f"{i}. **{f.filename}**")
            result_lines.append(f"   - –¢–∏–ø: {file_type}")
            result_lines.append(f"   - –†–∞–∑–º–µ—Ä: {size_str}")
            if f.page_count:
                result_lines.append(f"   - –°—Ç—Ä–∞–Ω–∏—Ü: {f.page_count}")
        
        logger.info(f"[ChatTools] list_case_files: {len(files)} —Ñ–∞–π–ª–æ–≤")
        return "\n".join(result_lines)
        
    except Exception as e:
        logger.error(f"[ChatTools] list_case_files error: {e}")
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {str(e)}"


@tool
def get_file_summary(filename: str) -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞:
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ
    - –ù—É–∂–µ–Ω –æ–±–∑–æ—Ä –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    
    Args:
        filename: –ò–º—è —Ñ–∞–π–ª–∞ (–ø–æ–ª–Ω–æ–µ –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ)
    
    Returns:
        –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    """
    global _db, _case_id, _rag_service
    
    if not _db or not _case_id:
        return "–û—à–∏–±–∫–∞: –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"
    
    try:
        from app.models.case import File as FileModel
        
        # –ò—â–µ–º —Ñ–∞–π–ª –ø–æ –∏–º–µ–Ω–∏ (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
        file = _db.query(FileModel).filter(
            FileModel.case_id == _case_id,
            FileModel.filename.ilike(f"%{filename}%")
        ).first()
        
        if not file:
            return f"–§–∞–π–ª '{filename}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–µ–ª–µ."
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ RAG
        documents = _rag_service.retrieve_context(
            case_id=_case_id,
            query=f"—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file.filename}",
            k=20,
            retrieval_strategy="multi_query",
            db=_db
        )
        
        if not documents:
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ '{file.filename}'."
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
        file_docs = [d for d in documents if d.metadata.get("source") == file.filename or d.metadata.get("file_id") == file.id]
        
        if not file_docs:
            file_docs = documents[:10]  # Fallback
        
        content = "\n".join([d.page_content for d in file_docs[:10]])
        
        result = f"üìÑ **{file.filename}**\n"
        result += f"–¢–∏–ø: {file.doc_type or '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω'}\n\n"
        result += f"**–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:**\n{content[:3000]}"
        
        if len(content) > 3000:
            result += "\n\n[... –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–∫—Ä–∞—â—ë–Ω ...]"
        
        logger.info(f"[ChatTools] get_file_summary: {file.filename}")
        return result
        
    except Exception as e:
        logger.error(f"[ChatTools] get_file_summary error: {e}")
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞: {str(e)}"


# =============================================================================
# Map-Reduce —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
# =============================================================================

@tool
def summarize_all_documents() -> str:
    """
    –°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –¥–µ–ª–µ (Map-Reduce).
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞:
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç "–æ —á—ë–º –≤—Å–µ —ç—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã?"
    - –ù—É–∂–µ–Ω –æ–±—â–∏–π –æ–±–∑–æ—Ä –¥–µ–ª–∞
    - –í–æ–ø—Ä–æ—Å "—á—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö?"
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç "—Ä–∞—Å—Å–∫–∞–∂–∏ –æ –¥–µ–ª–µ"
    
    –í–ê–ñ–ù–û: –≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –¥–µ–ª–µ,
    –¥–∞–∂–µ –µ—Å–ª–∏ –∏—Ö –º–Ω–æ–≥–æ (100+). –ò—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –¥–ª—è –æ–±–∑–æ—Ä–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
    
    Returns:
        –û–±—â–∏–π –æ–±–∑–æ—Ä –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –¥–µ–ª–µ
    """
    global _db, _case_id, _rag_service
    
    if not _db or not _case_id:
        return "–û—à–∏–±–∫–∞: –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"
    
    try:
        from app.models.case import File as FileModel
        from app.services.llm_factory import create_legal_llm
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # 1. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
        files = _db.query(FileModel).filter(
            FileModel.case_id == _case_id
        ).all()
        
        if not files:
            return "–í –¥–µ–ª–µ –Ω–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
        
        logger.info(f"[ChatTools] summarize_all_documents: –Ω–∞—á–∏–Ω–∞–µ–º Map-Reduce –¥–ª—è {len(files)} —Ñ–∞–π–ª–æ–≤")
        
        # 2. MAP: –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        llm = create_legal_llm(temperature=0.1)
        file_summaries = []
        
        for file in files:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Ñ–∞–π–ª–∞
                documents = _rag_service.retrieve_context(
                    case_id=_case_id,
                    query=f"–ø–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ {file.filename}",
                    k=30,
                    retrieval_strategy="multi_query",
                    db=_db
                )
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ñ–∞–π–ª—É
                file_docs = [d for d in documents if 
                            d.metadata.get("source") == file.filename or 
                            d.metadata.get("file_id") == str(file.id)]
                
                if not file_docs:
                    file_docs = documents[:5]
                
                content = "\n".join([d.page_content for d in file_docs[:15]])[:4000]
                
                if not content.strip():
                    file_summaries.append({
                        "filename": file.filename,
                        "doc_type": file.doc_type or "unknown",
                        "summary": "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ"
                    })
                    continue
                
                # –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª
                summary_prompt = f"""–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):

–î–æ–∫—É–º–µ–Ω—Ç: {file.filename}
–¢–∏–ø: {file.doc_type or '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω'}

–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:
{content}

–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:"""
                
                response = llm.invoke([
                    SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ö—Ä–∞—Ç–∫–æ –æ–ø–∏—Å—ã–≤–∞–π –¥–æ–∫—É–º–µ–Ω—Ç—ã."),
                    HumanMessage(content=summary_prompt)
                ])
                
                summary_text = response.content if hasattr(response, 'content') else str(response)
                
                file_summaries.append({
                    "filename": file.filename,
                    "doc_type": file.doc_type or "unknown",
                    "summary": summary_text.strip()
                })
                
            except Exception as e:
                logger.warning(f"[ChatTools] –û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ {file.filename}: {e}")
                file_summaries.append({
                    "filename": file.filename,
                    "doc_type": file.doc_type or "unknown",
                    "summary": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)[:50]}"
                })
        
        # 3. REDUCE: –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–±—â–∏–π –æ–±–∑–æ—Ä
        summaries_text = "\n\n".join([
            f"**{s['filename']}** ({s['doc_type']}): {s['summary']}"
            for s in file_summaries
        ])
        
        reduce_prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏–π –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–µ–ª–∞, —Å–æ—Å—Ç–∞–≤—å –æ–±—â–∏–π –æ–±–∑–æ—Ä:

{summaries_text}

–°–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±–∑–æ—Ä –¥–µ–ª–∞:
1. –û —á—ë–º —ç—Ç–æ –¥–µ–ª–æ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –ö–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –µ—Å—Ç—å (–ø–µ—Ä–µ—á–∏—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ)
3. –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
4. –û–±—â–∏–π –≤—ã–≤–æ–¥

–û–±–∑–æ—Ä:"""
        
        final_response = llm.invoke([
            SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –°–æ—Å—Ç–∞–≤–ª—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±–∑–æ—Ä—ã –¥–µ–ª."),
            HumanMessage(content=reduce_prompt)
        ])
        
        overview = final_response.content if hasattr(final_response, 'content') else str(final_response)
        
        result = f"üìã **–û–±–∑–æ—Ä –¥–µ–ª–∞ ({len(files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)**\n\n"
        result += overview
        result += f"\n\n---\n*–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(file_summaries)}*"
        
        logger.info(f"[ChatTools] summarize_all_documents: –∑–∞–≤–µ—Ä—à–µ–Ω–æ, {len(file_summaries)} —Ñ–∞–π–ª–æ–≤")
        return result
        
    except Exception as e:
        logger.error(f"[ChatTools] summarize_all_documents error: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±–∑–æ—Ä–∞: {str(e)}"


# =============================================================================
# –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
# =============================================================================

@tool
def extract_entities(entity_types: str = "all") -> str:
    """
    –ò–∑–≤–ª–µ—á—å —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–¥–∞—Ç—ã, –∏–º–µ–Ω–∞, —Å—É–º–º—ã, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏).
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞:
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç "–∫–∞–∫–∏–µ –¥–∞—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö?"
    - –ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤—Å–µ —Å—É–º–º—ã –∏–ª–∏ –∏–º–µ–Ω–∞
    - –í–æ–ø—Ä–æ—Å –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–∞—Ö
    
    Args:
        entity_types: –¢–∏–ø—ã —Å—É—â–Ω–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: dates, persons, organizations, amounts, all
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –ø–æ —Ç–∏–ø–∞–º
    """
    global _db, _case_id, _rag_service
    
    if not _rag_service or not _case_id:
        return "–û—à–∏–±–∫–∞: —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
    
    try:
        from app.services.llm_factory import create_legal_llm
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        documents = _rag_service.retrieve_context(
            case_id=_case_id,
            query="–∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –¥–∞—Ç—ã —Å—É–º–º—ã –∏–º–µ–Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏",
            k=50,
            retrieval_strategy="multi_query",
            db=_db
        )
        
        if not documents:
            return "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π."
        
        content = "\n".join([d.page_content for d in documents])[:8000]
        
        llm = create_legal_llm(temperature=0.0)
        
        prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–ª–µ–¥—É—é—â–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏:
- –î–∞—Ç—ã (–≤—Å–µ —É–ø–æ–º–∏–Ω–∞–µ–º—ã–µ –¥–∞—Ç—ã)
- –°—É–º–º—ã (–¥–µ–Ω–µ–∂–Ω—ã–µ —Å—É–º–º—ã)
- –õ–∏—Ü–∞ (–∏–º–µ–Ω–∞ –ª—é–¥–µ–π)
- –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π, –æ—Ä–≥–∞–Ω–æ–≤)

–¢–µ–∫—Å—Ç:
{content}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
üìÖ –î–ê–¢–´:
- –¥–∞—Ç–∞1
- –¥–∞—Ç–∞2

üí∞ –°–£–ú–ú–´:
- —Å—É–º–º–∞1
- —Å—É–º–º–∞2

üë§ –õ–ò–¶–ê:
- –∏–º—è1
- –∏–º—è2

üè¢ –û–†–ì–ê–ù–ò–ó–ê–¶–ò–ò:
- –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è1
- –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è2

–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏:"""
        
        response = llm.invoke([
            SystemMessage(content="–¢—ã –∏–∑–≤–ª–µ–∫–∞–µ—à—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."),
            HumanMessage(content=prompt)
        ])
        
        result = response.content if hasattr(response, 'content') else str(response)
        logger.info(f"[ChatTools] extract_entities: –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        return result
        
    except Exception as e:
        logger.error(f"[ChatTools] extract_entities error: {e}")
        return f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π: {str(e)}"


@tool
def find_contradictions() -> str:
    """
    –ù–∞–π—Ç–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –º–µ–∂–¥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –≤ –¥–µ–ª–µ.
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞:
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è—Ö
    - –ù—É–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã
    - –í–æ–ø—Ä–æ—Å –æ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è—Ö
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    """
    global _db, _case_id, _rag_service
    
    if not _rag_service or not _case_id:
        return "–û—à–∏–±–∫–∞: —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
    
    try:
        from app.services.llm_factory import create_legal_llm
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –±–æ–ª—å—à–∏–º k –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        documents = _rag_service.retrieve_context(
            case_id=_case_id,
            query="—Ñ–∞–∫—Ç—ã –¥–∞—Ç—ã —Å—É–º–º—ã —É—Å–ª–æ–≤–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞",
            k=100,
            retrieval_strategy="multi_query",
            db=_db
        )
        
        if not documents:
            return "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π."
        
        content = "\n\n".join([
            f"[{d.metadata.get('source', 'unknown')}]: {d.page_content}"
            for d in documents
        ])[:12000]
        
        llm = create_legal_llm(temperature=0.1)
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –Ω–∞–π–¥–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è:

{content}

–ù–∞–π–¥–∏:
1. –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –≤ –¥–∞—Ç–∞—Ö –º–µ–∂–¥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
2. –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –≤ —Å—É–º–º–∞—Ö
3. –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –≤ —Ñ–∞–∫—Ç–∞—Ö
4. –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤ —É—Å–ª–æ–≤–∏—è—Ö

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è —É–∫–∞–∂–∏:
- –ß—Ç–æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç
- –í –∫–∞–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
- –°—É—Ç—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è

–ï—Å–ª–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –Ω–µ—Ç, –Ω–∞–ø–∏—à–∏ "–Ø–≤–Ω—ã—Ö –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ".

–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:"""
        
        response = llm.invoke([
            SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –ù–∞—Ö–æ–¥–∏—à—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö."),
            HumanMessage(content=prompt)
        ])
        
        result = response.content if hasattr(response, 'content') else str(response)
        logger.info(f"[ChatTools] find_contradictions: –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        return f"üîç **–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π**\n\n{result}"
        
    except Exception as e:
        logger.error(f"[ChatTools] find_contradictions error: {e}")
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π: {str(e)}"


@tool
def analyze_risks() -> str:
    """
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏ –≤ –¥–µ–ª–µ.
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞:
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Ä–∏—Å–∫–∞—Ö
    - –ù—É–∂–Ω–∞ –æ—Ü–µ–Ω–∫–∞ –ø—Ä–∞–≤–æ–≤—ã—Ö —Ä–∏—Å–∫–æ–≤
    - –í–æ–ø—Ä–æ—Å "–∫–∞–∫–∏–µ —Ä–∏—Å–∫–∏?"
    
    Returns:
        –ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤ —Å –æ—Ü–µ–Ω–∫–æ–π —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç–∏
    """
    global _db, _case_id, _rag_service
    
    if not _rag_service or not _case_id:
        return "–û—à–∏–±–∫–∞: —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
    
    try:
        from app.services.llm_factory import create_legal_llm
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        documents = _rag_service.retrieve_context(
            case_id=_case_id,
            query="—É—Å–ª–æ–≤–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å —Å—Ä–æ–∫–∏ —à—Ç—Ä–∞—Ñ—ã —Ä–∏—Å–∫–∏",
            k=50,
            retrieval_strategy="multi_query",
            db=_db
        )
        
        if not documents:
            return "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤."
        
        content = "\n".join([d.page_content for d in documents])[:8000]
        
        llm = create_legal_llm(temperature=0.1)
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:

{content}

–û—Ü–µ–Ω–∏ —Ä–∏—Å–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:
1. üî¥ –í—ã—Å–æ–∫–∏–µ —Ä–∏—Å–∫–∏ (–∫—Ä–∏—Ç–∏—á–Ω—ã–µ)
2. üü° –°—Ä–µ–¥–Ω–∏–µ —Ä–∏—Å–∫–∏ (—Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è)
3. üü¢ –ù–∏–∑–∫–∏–µ —Ä–∏—Å–∫–∏ (–Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ)

–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∏—Å–∫–∞ —É–∫–∞–∂–∏:
- –û–ø–∏—Å–∞–Ω–∏–µ —Ä–∏—Å–∫–∞
- –í–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏

–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤:"""
        
        response = llm.invoke([
            SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –û—Ü–µ–Ω–∏–≤–∞–µ—à—å –ø—Ä–∞–≤–æ–≤—ã–µ —Ä–∏—Å–∫–∏."),
            HumanMessage(content=prompt)
        ])
        
        result = response.content if hasattr(response, 'content') else str(response)
        logger.info(f"[ChatTools] analyze_risks: –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        return f"‚ö†Ô∏è **–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤**\n\n{result}"
        
    except Exception as e:
        logger.error(f"[ChatTools] analyze_risks error: {e}")
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤: {str(e)}"


@tool
def build_timeline() -> str:
    """
    –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é —Å–æ–±—ã—Ç–∏–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞:
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏–∏
    - –ù—É–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π
    - –í–æ–ø—Ä–æ—Å "–∫–æ–≥–¥–∞ —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ?"
    
    Returns:
        –•—Ä–æ–Ω–æ–ª–æ–≥–∏—è —Å–æ–±—ã—Ç–∏–π —Å –¥–∞—Ç–∞–º–∏
    """
    global _db, _case_id, _rag_service
    
    if not _rag_service or not _case_id:
        return "–û—à–∏–±–∫–∞: —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
    
    try:
        from app.services.llm_factory import create_legal_llm
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –¥–∞—Ç—ã
        documents = _rag_service.retrieve_context(
            case_id=_case_id,
            query="–¥–∞—Ç–∞ —Å–æ–±—ã—Ç–∏–µ –ø—Ä–æ–∏–∑–æ—à–ª–æ –∑–∞–∫–ª—é—á–µ–Ω –ø–æ–¥–ø–∏—Å–∞–Ω –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—É—á–µ–Ω",
            k=50,
            retrieval_strategy="multi_query",
            db=_db
        )
        
        if not documents:
            return "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏–∏."
        
        content = "\n".join([d.page_content for d in documents])[:8000]
        
        llm = create_legal_llm(temperature=0.0)
        
        prompt = f"""–ü–æ—Å—Ç—Ä–æ–π —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é —Å–æ–±—ã—Ç–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:

{content}

–§–æ—Ä–º–∞—Ç:
üìÖ –î–ê–¢–ê ‚Äî –°–æ–±—ã—Ç–∏–µ (–∏—Å—Ç–æ—á–Ω–∏–∫)

–û—Ç—Å–æ—Ä—Ç–∏—Ä—É–π —Å–æ–±—ã—Ç–∏—è –ø–æ –¥–∞—Ç–µ –æ—Ç —Ä–∞–Ω–Ω–∏—Ö –∫ –ø–æ–∑–¥–Ω–∏–º.
–ï—Å–ª–∏ —Ç–æ—á–Ω–∞—è –¥–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞, —É–∫–∞–∂–∏ –ø—Ä–∏–º–µ—Ä–Ω—ã–π –ø–µ—Ä–∏–æ–¥.

–•—Ä–æ–Ω–æ–ª–æ–≥–∏—è:"""
        
        response = llm.invoke([
            SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –°—Ç—Ä–æ–∏—à—å —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏–∏ —Å–æ–±—ã—Ç–∏–π."),
            HumanMessage(content=prompt)
        ])
        
        result = response.content if hasattr(response, 'content') else str(response)
        logger.info(f"[ChatTools] build_timeline: –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        return f"üìÖ **–•—Ä–æ–Ω–æ–ª–æ–≥–∏—è —Å–æ–±—ã—Ç–∏–π**\n\n{result}"
        
    except Exception as e:
        logger.error(f"[ChatTools] build_timeline error: {e}")
        return f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏–∏: {str(e)}"


# =============================================================================
# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø–æ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—è–º)
# =============================================================================

def get_garant_tools():
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã GARANT (–µ—Å–ª–∏ legal_research=True)"""
    try:
        from app.services.langchain_agents.garant_tools import search_garant, get_garant_full_text
        return [search_garant, get_garant_full_text]
    except ImportError:
        logger.warning("[ChatTools] GARANT tools not available")
        return []


def get_web_search_tool():
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤–µ–±-–ø–æ–∏—Å–∫–∞ (–µ—Å–ª–∏ web_search=True)"""
    try:
        from app.services.langchain_agents.web_research_tool import web_research_tool
        return [web_research_tool]
    except ImportError:
        logger.warning("[ChatTools] Web search tool not available")
        return []


# =============================================================================
# –§–∞–±—Ä–∏–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
# =============================================================================

def get_chat_tools(
    db: Session,
    rag_service,
    case_id: str,
    legal_research: bool = False,
    web_search: bool = False
) -> List:
    """
    –ü–æ–ª—É—á–∏—Ç—å –Ω–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —á–∞—Ç–∞.
    
    Args:
        db: SQLAlchemy —Å–µ—Å—Å–∏—è
        rag_service: RAG —Å–µ—Ä–≤–∏—Å
        case_id: ID –¥–µ–ª–∞
        legal_research: –í–∫–ª—é—á–∏—Ç—å GARANT
        web_search: –í–∫–ª—é—á–∏—Ç—å –≤–µ–±-–ø–æ–∏—Å–∫
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    """
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    initialize_chat_tools(db, rag_service, case_id)
    
    # –ë–∞–∑–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω—ã)
    tools = [
        search_documents,
        list_case_files,
        get_file_summary,
        summarize_all_documents,
        extract_entities,
        find_contradictions,
        analyze_risks,
        build_timeline,
    ]
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    if legal_research:
        tools.extend(get_garant_tools())
        logger.info("[ChatTools] GARANT tools enabled")
    
    if web_search:
        tools.extend(get_web_search_tool())
        logger.info("[ChatTools] Web search tool enabled")
    
    logger.info(f"[ChatTools] Initialized {len(tools)} tools for case {case_id}")
    return tools

