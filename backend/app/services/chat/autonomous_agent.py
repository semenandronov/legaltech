"""
Autonomous Chat Agent - –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞–≥–µ–Ω—Ç —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º

–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
1. –ü–û–ù–ò–ú–ê–ù–ò–ï: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
2. –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï: –°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –ø–æ–¥ –ö–û–ù–ö–†–ï–¢–ù–£–Æ –∑–∞–¥–∞—á—É (–Ω–µ –≤—ã–±–æ—Ä –∏–∑ –≥–æ—Ç–æ–≤—ã—Ö)
3. –í–´–ü–û–õ–ù–ï–ù–ò–ï: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —à–∞–≥–æ–≤ (–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ò–õ–ò –∫–∞—Å—Ç–æ–º–Ω—ã–µ LLM-–∑–∞–ø—Ä–æ—Å—ã)
4. –°–ò–ù–¢–ï–ó: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Å–≤—è–∑–Ω—ã–π –æ—Ç–≤–µ—Ç

–ê–≥–µ–Ω—Ç –ù–ï –æ–≥—Ä–∞–Ω–∏—á–µ–Ω —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
–û–Ω –º–æ–∂–µ—Ç —Ä–µ—à–∏—Ç—å –õ–Æ–ë–£–Æ –∑–∞–¥–∞—á—É, —Å–æ–∑–¥–∞–≤–∞—è –ø–ª–∞–Ω –ø–æ–¥ –Ω–µ—ë.
"""
from typing import AsyncGenerator, Optional, List, Dict, Any
from dataclasses import dataclass, field
from enum import Enum
from sqlalchemy.orm import Session
import logging
import json
import asyncio

from app.services.chat.events import SSESerializer
from app.services.rag_service import RAGService
from app.models.user import User

logger = logging.getLogger(__name__)


class TaskComplexity(Enum):
    """–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏"""
    SIMPLE = "simple"           # –ü—Ä–æ—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å ‚Äî –±—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å
    MODERATE = "moderate"       # –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å ‚Äî 2-3 —à–∞–≥–∞
    COMPLEX = "complex"         # –°–ª–æ–∂–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–ª–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ


class StepType(Enum):
    """–¢–∏–ø —à–∞–≥–∞ –≤ –ø–ª–∞–Ω–µ"""
    SEARCH = "search"                   # –ü–æ–∏—Å–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
    SUMMARIZE = "summarize"             # –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
    EXTRACT = "extract"                 # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π
    ANALYZE = "analyze"                 # –ê–Ω–∞–ª–∏–∑ (—Ä–∏—Å–∫–∏, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è)
    COMPARE = "compare"                 # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
    GENERATE = "generate"               # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    LEGAL_RESEARCH = "legal_research"   # –ü–æ–∏—Å–∫ –≤ –ø—Ä–∞–≤–æ–≤—ã—Ö –±–∞–∑–∞—Ö
    WEB_SEARCH = "web_search"           # –í–µ–±-–ø–æ–∏—Å–∫
    CUSTOM = "custom"                   # –ö–∞—Å—Ç–æ–º–Ω—ã–π LLM-–∑–∞–ø—Ä–æ—Å


@dataclass
class PlanStep:
    """–®–∞–≥ –ø–ª–∞–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
    step_id: int
    step_type: StepType
    description: str                    # –ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å
    instruction: str                    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è LLM
    query: Optional[str] = None         # –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
    depends_on: List[int] = field(default_factory=list)  # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥—Ä—É–≥–∏—Ö —à–∞–≥–æ–≤
    params: Dict[str, Any] = field(default_factory=dict)  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã


@dataclass
class ExecutionPlan:
    """–ü–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏"""
    task_understanding: str             # –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
    complexity: TaskComplexity          # –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    steps: List[PlanStep]               # –®–∞–≥–∏ –ø–ª–∞–Ω–∞
    expected_output: str                # –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞


@dataclass
class StepResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —à–∞–≥–∞"""
    step_id: int
    success: bool
    content: str
    sources: List[str] = field(default_factory=list)


class AutonomousChatAgent:
    """
    –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞–≥–µ–Ω—Ç —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
    
    –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç ReActChatAgent —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏,
    —ç—Ç–æ—Ç –∞–≥–µ–Ω—Ç:
    1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á—É
    2. –°–æ–∑–¥–∞—ë—Ç –ö–ê–°–¢–û–ú–ù–´–ô –ø–ª–∞–Ω –ø–æ–¥ –Ω–µ—ë
    3. –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–ª–∞–Ω –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
    4. –ú–æ–∂–µ—Ç —Ä–µ—à–∏—Ç—å –õ–Æ–ë–£–Æ –∑–∞–¥–∞—á—É
    """
    
    def __init__(
        self,
        case_id: str,
        db: Session,
        rag_service: RAGService,
        current_user: Optional[User] = None,
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª–∏
        legal_research: bool = False,
        deep_think: bool = False,
        web_search: bool = False,
        chat_history: Optional[List[Dict[str, str]]] = None
    ):
        self.case_id = case_id
        self.db = db
        self.rag_service = rag_service
        self.current_user = current_user
        self.legal_research = legal_research
        self.deep_think = deep_think
        self.web_search = web_search
        self.chat_history = chat_history or []
        
        # –°–æ–∑–¥–∞—ë–º LLM
        self.llm = self._create_llm()
        
        # –ö—ç—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —à–∞–≥–æ–≤
        self.step_results: Dict[int, StepResult] = {}
        
        logger.info(
            f"[AutonomousAgent] Initialized for case {case_id} "
            f"(deep_think={deep_think}, legal_research={legal_research}, web_search={web_search})"
        )
    
    def _create_llm(self):
        """–°–æ–∑–¥–∞—Ç—å LLM"""
        from app.services.llm_factory import create_legal_llm
        from app.config import config
        
        if self.deep_think:
            model = config.GIGACHAT_PRO_MODEL or "GigaChat-Pro"
            return create_legal_llm(model=model, temperature=0.2)
        return create_legal_llm(temperature=0.1)
    
    async def handle(self, question: str) -> AsyncGenerator[str, None]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ—Ç FULL PATH (4 —Ñ–∞–∑—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è):
        1. UNDERSTANDING ‚Äî –≥–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        2. PLANNING ‚Äî —Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –ø–æ–¥ –∑–∞–¥–∞—á—É
        3. EXECUTION ‚Äî –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —à–∞–≥–æ–≤
        4. SYNTHESIS ‚Äî —Å–∏–Ω—Ç–µ–∑ –æ—Ç–≤–µ—Ç–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        –ê–≥–µ–Ω—Ç –°–ê–ú –ø–ª–∞–Ω–∏—Ä—É–µ—Ç –ø–æ–¥ –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É, –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏.
        """
        try:
            logger.info(f"[AutonomousAgent] Processing: {question[:100]}...")
            
            # ===== –§–ê–ó–ê 1: –ü–û–ù–ò–ú–ê–ù–ò–ï =====
            yield SSESerializer.reasoning(
                phase="understanding",
                step=1,
                total_steps=4,
                content="–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∞—à –∑–∞–ø—Ä–æ—Å..."
            )
            
            understanding = await self._understand_request(question)
            
            yield SSESerializer.reasoning(
                phase="understanding",
                step=1,
                total_steps=4,
                content=f"–ü–æ–Ω—è–ª –∑–∞–¥–∞—á—É: {understanding['summary']}"
            )
            
            # ===== –§–ê–ó–ê 2: –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï =====
            yield SSESerializer.reasoning(
                phase="planning",
                step=2,
                total_steps=4,
                content="–°–æ–∑–¥–∞—é –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è..."
            )
            
            plan = await self._create_plan(question, understanding)
            
            yield SSESerializer.reasoning(
                phase="planning",
                step=2,
                total_steps=4,
                content=f"–ü–ª–∞–Ω –≥–æ—Ç–æ–≤: {len(plan.steps)} —à–∞–≥–æ–≤ ({plan.complexity.value})"
            )
            
            # ===== –§–ê–ó–ê 3: –í–´–ü–û–õ–ù–ï–ù–ò–ï =====
            yield SSESerializer.reasoning(
                phase="execution",
                step=3,
                total_steps=4,
                content="–í—ã–ø–æ–ª–Ω—è—é –ø–ª–∞–Ω..."
            )
            
            async for event in self._execute_plan(plan):
                yield event
            
            # ===== –§–ê–ó–ê 4: –°–ò–ù–¢–ï–ó =====
            yield SSESerializer.reasoning(
                phase="synthesis",
                step=4,
                total_steps=4,
                content="–§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç..."
            )
            
            answer = await self._synthesize_answer(question, plan)
            
            # –°—Ç—Ä–∏–º–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            yield SSESerializer.text_delta(answer)
            
            logger.info(f"[AutonomousAgent] Completed successfully (FULL PATH)")
            
        except Exception as e:
            logger.error(f"[AutonomousAgent] Error: {e}", exc_info=True)
            yield SSESerializer.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
    
    # =========================================================================
    # –§–ê–ó–ê 1: –ü–û–ù–ò–ú–ê–ù–ò–ï
    # =========================================================================
    
    async def _understand_request(self, question: str) -> Dict[str, Any]:
        """
        –ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç:
        - –ß—Ç–æ –∏–º–µ–Ω–Ω–æ —Ö–æ—á–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        - –ö–∞–∫–æ–π —Ç–∏–ø –∑–∞–¥–∞—á–∏ (–≤–æ–ø—Ä–æ—Å, –∞–Ω–∞–ª–∏–∑, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è)
        - –ö–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω—É–∂–Ω—ã
        - –ö–∞–∫–æ–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ–∂–∏–¥–∞–µ—Ç—Å—è
        """
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –¥–µ–ª–µ
        case_context = await self._get_case_context()
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏:

–ó–ê–ü–†–û–°: {question}

–ö–û–ù–¢–ï–ö–°–¢ –î–ï–õ–ê:
{case_context}

–ò–°–¢–û–†–ò–Ø –ß–ê–¢–ê (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è):
{self._format_chat_history()}

–û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "summary": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á—Ç–æ —Ö–æ—á–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)",
    "task_type": "question|analysis|comparison|generation|search|overview",
    "requires_all_documents": true/false,
    "requires_legal_research": true/false,
    "requires_web_search": true/false,
    "key_entities": ["—Å—É—â–Ω–æ—Å—Ç–∏ –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏"],
    "expected_output_format": "–æ–ø–∏—Å–∞–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞",
    "complexity": "simple|moderate|complex",
    "reasoning": "–ø–æ—á–µ–º—É —Ç–∞–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"
}}

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON, –±–µ–∑ markdown."""

        response = self.llm.invoke([
            SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."),
            HumanMessage(content=prompt)
        ])
        
        try:
            # –ü–∞—Ä—Å–∏–º JSON
            content = response.content if hasattr(response, 'content') else str(response)
            # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ markdown-–æ–±—ë—Ä—Ç–∫–∏
            content = content.strip()
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
            
            understanding = json.loads(content)
            logger.info(f"[AutonomousAgent] Understanding: {understanding.get('summary', 'N/A')}")
            return understanding
            
        except json.JSONDecodeError as e:
            logger.warning(f"[AutonomousAgent] Failed to parse understanding: {e}")
            # Fallback
            return {
                "summary": question[:100],
                "task_type": "question",
                "requires_all_documents": False,
                "requires_legal_research": self.legal_research,
                "requires_web_search": self.web_search,
                "key_entities": [],
                "expected_output_format": "—Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç",
                "complexity": "moderate",
                "reasoning": "–Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å"
            }
    
    async def _get_case_context(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –¥–µ–ª–µ (—Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)"""
        try:
            from app.models.case import File as FileModel, Case
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–µ–ª–µ
            case = self.db.query(Case).filter(Case.id == self.case_id).first()
            case_info = f"–î–µ–ª–æ: {case.name if case else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}\n"
            
            # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
            files = self.db.query(FileModel).filter(
                FileModel.case_id == self.case_id
            ).all()
            
            if files:
                case_info += f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(files)}\n"
                case_info += "–§–∞–π–ª—ã:\n"
                for f in files[:10]:  # –ü–µ—Ä–≤—ã–µ 10
                    case_info += f"- {f.filename} ({f.file_type or 'unknown'})\n"
                if len(files) > 10:
                    case_info += f"... –∏ –µ—â—ë {len(files) - 10} —Ñ–∞–π–ª–æ–≤\n"
            else:
                case_info += "–î–æ–∫—É–º–µ–Ω—Ç–æ–≤: 0\n"
            
            return case_info
            
        except Exception as e:
            logger.warning(f"[AutonomousAgent] Failed to get case context: {e}")
            return "–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–µ–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
    
    def _format_chat_history(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞"""
        if not self.chat_history:
            return "–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞"
        
        formatted = []
        for msg in self.chat_history[-5:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5
            role = msg.get("role", "unknown")
            content = msg.get("content", "")[:200]
            formatted.append(f"{role}: {content}")
        
        return "\n".join(formatted)
    
    # =========================================================================
    # –§–ê–ó–ê 2: –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï
    # =========================================================================
    
    async def _create_plan(self, question: str, understanding: Dict[str, Any]) -> ExecutionPlan:
        """
        –°–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–¥ –ö–û–ù–ö–†–ï–¢–ù–£–Æ –∑–∞–¥–∞—á—É.
        
        –ü–ª–∞–Ω —Å–æ–∑–¥–∞—ë—Ç—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏, –Ω–µ –∏–∑ –≥–æ—Ç–æ–≤—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤.
        """
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        capabilities = self._get_available_capabilities()
        
        prompt = f"""–°–æ–∑–¥–∞–π –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏.

–ó–ê–î–ê–ß–ê: {question}

–ü–û–ù–ò–ú–ê–ù–ò–ï –ó–ê–î–ê–ß–ò:
{json.dumps(understanding, ensure_ascii=False, indent=2)}

–î–û–°–¢–£–ü–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:
{capabilities}

–ü–†–ê–í–ò–õ–ê –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–Ø:
1. –ö–∞–∂–¥—ã–π —à–∞–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ú –∏ –í–´–ü–û–õ–ù–ò–ú–´–ú
2. –®–∞–≥–∏ –º–æ–≥—É—Ç –∑–∞–≤–∏—Å–µ—Ç—å –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞ (depends_on)
3. –ò—Å–ø–æ–ª—å–∑—É–π –º–∏–Ω–∏–º—É–º —à–∞–≥–æ–≤ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏
4. –î–ª—è –æ–±–∑–æ—Ä–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–∏ —Ä–∞–±–æ—Ç—É —Å–æ –í–°–ï–ú–ò –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
5. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ ‚Äî —Å–Ω–∞—á–∞–ª–∞ —Å–æ–±–µ—Ä–∏ –¥–∞–Ω–Ω—ã–µ, –ø–æ—Ç–æ–º —Å—Ä–∞–≤–Ω–∏–≤–∞–π

–û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "steps": [
        {{
            "step_id": 1,
            "step_type": "search|summarize|extract|analyze|compare|generate|legal_research|web_search|custom",
            "description": "–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç —à–∞–≥",
            "instruction": "–î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
            "query": "–ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –µ—Å–ª–∏ –Ω—É–∂–µ–Ω",
            "depends_on": [],
            "params": {{}}
        }}
    ],
    "expected_output": "–æ–ø–∏—Å–∞–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
}}

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON."""

        response = self.llm.invoke([
            SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á. –°–æ–∑–¥–∞–≤–∞–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–ª–∞–Ω—ã."),
            HumanMessage(content=prompt)
        ])
        
        try:
            content = response.content if hasattr(response, 'content') else str(response)
            content = content.strip()
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
            
            plan_data = json.loads(content)
            
            # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç—ã —à–∞–≥–æ–≤
            steps = []
            for step_data in plan_data.get("steps", []):
                step = PlanStep(
                    step_id=step_data.get("step_id", len(steps) + 1),
                    step_type=StepType(step_data.get("step_type", "custom")),
                    description=step_data.get("description", ""),
                    instruction=step_data.get("instruction", ""),
                    query=step_data.get("query"),
                    depends_on=step_data.get("depends_on", []),
                    params=step_data.get("params", {})
                )
                steps.append(step)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å
            complexity = TaskComplexity(understanding.get("complexity", "moderate"))
            
            plan = ExecutionPlan(
                task_understanding=understanding.get("summary", ""),
                complexity=complexity,
                steps=steps,
                expected_output=plan_data.get("expected_output", "")
            )
            
            logger.info(f"[AutonomousAgent] Created plan with {len(steps)} steps")
            return plan
            
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"[AutonomousAgent] Failed to parse plan: {e}, using fallback")
            return self._create_fallback_plan(question, understanding)
    
    def _get_available_capabilities(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"""
        caps = """
1. SEARCH (search) ‚Äî –ü–æ–∏—Å–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –¥–µ–ª–∞
   - –ú–æ–∂–µ—Ç –∏—Å–∫–∞—Ç—å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º, —Ñ—Ä–∞–∑–∞–º, —Ç–µ–º–∞–º
   - –ü–∞—Ä–∞–º–µ—Ç—Ä k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (5-100)

2. SUMMARIZE (summarize) ‚Äî –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
   - –ú–æ–∂–µ—Ç —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç –∏–ª–∏ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
   - –ü–∞—Ä–∞–º–µ—Ç—Ä: all_documents=true –¥–ª—è Map-Reduce –ø–æ –≤—Å–µ–º

3. EXTRACT (extract) ‚Äî –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π
   - –î–∞—Ç—ã, —Å—É–º–º—ã, –∏–º–µ–Ω–∞, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
   - –ü–∞—Ä–∞–º–µ—Ç—Ä: entity_types (dates, amounts, persons, organizations)

4. ANALYZE (analyze) ‚Äî –ê–Ω–∞–ª–∏–∑
   - –†–∏—Å–∫–∏, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è, —Å–∏–ª—å–Ω—ã–µ/—Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
   - –ü–∞—Ä–∞–º–µ—Ç—Ä: analysis_type (risks, contradictions, strengths, weaknesses)

5. COMPARE (compare) ‚Äî –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
   - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –ø–æ–∑–∏—Ü–∏–π, —É—Å–ª–æ–≤–∏–π
   - –ü–∞—Ä–∞–º–µ—Ç—Ä: compare_what (documents, positions, conditions)

6. GENERATE (generate) ‚Äî –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
   - –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
   - –ü–∞—Ä–∞–º–µ—Ç—Ä: output_type (summary, arguments, recommendations)

7. CUSTOM (custom) ‚Äî –ö–∞—Å—Ç–æ–º–Ω—ã–π –∑–∞–ø—Ä–æ—Å
   - –õ—é–±–æ–π –∑–∞–ø—Ä–æ—Å –∫ LLM —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   - –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç
"""
        
        if self.legal_research:
            caps += """
8. LEGAL_RESEARCH (legal_research) ‚Äî –ü–æ–∏—Å–∫ –≤ –ø—Ä–∞–≤–æ–≤—ã—Ö –±–∞–∑–∞—Ö (–ì–ê–†–ê–ù–¢)
   - –ü–æ–∏—Å–∫ –∑–∞–∫–æ–Ω–æ–≤, —Å—Ç–∞—Ç–µ–π, —Å—É–¥–µ–±–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–∏
"""
        
        if self.web_search:
            caps += """
9. WEB_SEARCH (web_search) ‚Äî –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
   - –ê–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –Ω–æ–≤–æ—Å—Ç–∏, –ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç—ã
"""
        
        return caps
    
    def _create_fallback_plan(self, question: str, understanding: Dict[str, Any]) -> ExecutionPlan:
        """–°–æ–∑–¥–∞—Ç—å fallback –ø–ª–∞–Ω"""
        steps = [
            PlanStep(
                step_id=1,
                step_type=StepType.SEARCH,
                description="–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                instruction="–ù–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
                query=question,
                params={"k": 20}
            ),
            PlanStep(
                step_id=2,
                step_type=StepType.GENERATE,
                description="–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞",
                instruction="–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                depends_on=[1]
            )
        ]
        
        return ExecutionPlan(
            task_understanding=understanding.get("summary", question),
            complexity=TaskComplexity.MODERATE,
            steps=steps,
            expected_output="–û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"
        )
    
    # =========================================================================
    # –§–ê–ó–ê 3: –í–´–ü–û–õ–ù–ï–ù–ò–ï
    # =========================================================================
    
    async def _execute_plan(self, plan: ExecutionPlan) -> AsyncGenerator[str, None]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–ª–∞–Ω.
        
        –®–∞–≥–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è —Å —É—á—ë—Ç–æ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—ç—à–∏—Ä—É—é—Ç—Å—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–∞—Ö.
        """
        total_steps = len(plan.steps)
        
        for i, step in enumerate(plan.steps, 1):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            await self._wait_for_dependencies(step.depends_on)
            
            yield SSESerializer.reasoning(
                phase="execution",
                step=3,
                total_steps=4,
                content=f"–®–∞–≥ {i}/{total_steps}: {step.description}"
            )
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —à–∞–≥
            result = await self._execute_step(step)
            self.step_results[step.step_id] = result
            
            if not result.success:
                logger.warning(f"[AutonomousAgent] Step {step.step_id} failed: {result.content[:100]}")
    
    async def _wait_for_dependencies(self, depends_on: List[int]):
        """–î–æ–∂–¥–∞—Ç—å—Å—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º—ã—Ö —à–∞–≥–æ–≤"""
        for dep_id in depends_on:
            while dep_id not in self.step_results:
                await asyncio.sleep(0.1)
    
    async def _execute_step(self, step: PlanStep) -> StepResult:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–∏–Ω —à–∞–≥ –ø–ª–∞–Ω–∞.
        
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç —Å–ø–æ—Å–æ–± –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
        - –ì–æ—Ç–æ–≤—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (–µ—Å–ª–∏ –ø–æ–¥—Ö–æ–¥–∏—Ç)
        - –ö–∞—Å—Ç–æ–º–Ω—ã–π LLM-–∑–∞–ø—Ä–æ—Å (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        """
        try:
            if step.step_type == StepType.SEARCH:
                return await self._execute_search(step)
            elif step.step_type == StepType.SUMMARIZE:
                return await self._execute_summarize(step)
            elif step.step_type == StepType.EXTRACT:
                return await self._execute_extract(step)
            elif step.step_type == StepType.ANALYZE:
                return await self._execute_analyze(step)
            elif step.step_type == StepType.COMPARE:
                return await self._execute_compare(step)
            elif step.step_type == StepType.GENERATE:
                return await self._execute_generate(step)
            elif step.step_type == StepType.LEGAL_RESEARCH:
                return await self._execute_legal_research(step)
            elif step.step_type == StepType.WEB_SEARCH:
                return await self._execute_web_search(step)
            else:  # CUSTOM
                return await self._execute_custom(step)
                
        except Exception as e:
            logger.error(f"[AutonomousAgent] Step {step.step_id} error: {e}")
            return StepResult(
                step_id=step.step_id,
                success=False,
                content=f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}"
            )
    
    async def _execute_search(self, step: PlanStep) -> StepResult:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö"""
        query = step.query or step.instruction
        k = step.params.get("k", 20)
        
        documents = self.rag_service.retrieve_context(
            case_id=self.case_id,
            query=query,
            k=k,
            retrieval_strategy="multi_query",
            db=self.db
        )
        
        if not documents:
            return StepResult(
                step_id=step.step_id,
                success=True,
                content="–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        content = self.rag_service.format_sources_for_prompt(documents, max_context_chars=8000)
        sources = list(set(d.metadata.get("source", "unknown") for d in documents))
        
        return StepResult(
            step_id=step.step_id,
            success=True,
            content=content,
            sources=sources
        )
    
    async def _execute_summarize(self, step: PlanStep) -> StepResult:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é"""
        from langchain_core.messages import HumanMessage, SystemMessage
        
        all_documents = step.params.get("all_documents", False)
        
        if all_documents:
            # Map-Reduce –ø–æ –≤—Å–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
            return await self._summarize_all_documents()
        else:
            # –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤
            context = self._get_context_from_dependencies(step.depends_on)
            
            response = self.llm.invoke([
                SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É."),
                HumanMessage(content=f"–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π:\n\n{context}\n\n–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {step.instruction}")
            ])
            
            return StepResult(
                step_id=step.step_id,
                success=True,
                content=response.content if hasattr(response, 'content') else str(response)
            )
    
    async def _summarize_all_documents(self) -> StepResult:
        """Map-Reduce —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        from app.models.case import File as FileModel
        from langchain_core.messages import HumanMessage, SystemMessage
        
        files = self.db.query(FileModel).filter(
            FileModel.case_id == self.case_id
        ).all()
        
        if not files:
            return StepResult(step_id=0, success=True, content="–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # MAP: –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        summaries = []
        for file in files:
            docs = self.rag_service.retrieve_context(
                case_id=self.case_id,
                query=f"—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ {file.filename}",
                k=20,
                db=self.db
            )
            
            if docs:
                content = "\n".join([d.page_content for d in docs[:10]])[:3000]
                
                response = self.llm.invoke([
                    SystemMessage(content="–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."),
                    HumanMessage(content=f"–î–æ–∫—É–º–µ–Ω—Ç: {file.filename}\n\n{content}")
                ])
                
                summary = response.content if hasattr(response, 'content') else str(response)
                summaries.append(f"**{file.filename}**: {summary}")
        
        # REDUCE: –û–±—ä–µ–¥–∏–Ω—è–µ–º
        combined = "\n\n".join(summaries)
        
        response = self.llm.invoke([
            SystemMessage(content="–°–æ—Å—Ç–∞–≤—å –æ–±—â–∏–π –æ–±–∑–æ—Ä –¥–µ–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."),
            HumanMessage(content=f"–û–ø–∏—Å–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n\n{combined}\n\n–°–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±–∑–æ—Ä –¥–µ–ª–∞.")
        ])
        
        return StepResult(
            step_id=0,
            success=True,
            content=response.content if hasattr(response, 'content') else str(response),
            sources=[f.filename for f in files]
        )
    
    async def _execute_extract(self, step: PlanStep) -> StepResult:
        """–ò–∑–≤–ª–µ—á—å —Å—É—â–Ω–æ—Å—Ç–∏"""
        from langchain_core.messages import HumanMessage, SystemMessage
        
        entity_types = step.params.get("entity_types", ["dates", "amounts", "persons", "organizations"])
        context = self._get_context_from_dependencies(step.depends_on)
        
        if not context:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫
            docs = self.rag_service.retrieve_context(
                case_id=self.case_id,
                query=step.query or "–∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –¥–∞—Ç—ã —Å—É–º–º—ã –∏–º–µ–Ω–∞",
                k=50,
                db=self.db
            )
            context = "\n".join([d.page_content for d in docs])[:8000]
        
        prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–ª–µ–¥—É—é—â–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏: {', '.join(entity_types)}

–¢–µ–∫—Å—Ç:
{context}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {step.instruction}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
üìÖ –î–ê–¢–´: ...
üí∞ –°–£–ú–ú–´: ...
üë§ –õ–ò–¶–ê: ...
üè¢ –û–†–ì–ê–ù–ò–ó–ê–¶–ò–ò: ..."""

        response = self.llm.invoke([
            SystemMessage(content="–¢—ã –∏–∑–≤–ª–µ–∫–∞–µ—à—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."),
            HumanMessage(content=prompt)
        ])
        
        return StepResult(
            step_id=step.step_id,
            success=True,
            content=response.content if hasattr(response, 'content') else str(response)
        )
    
    async def _execute_analyze(self, step: PlanStep) -> StepResult:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑"""
        from langchain_core.messages import HumanMessage, SystemMessage
        
        analysis_type = step.params.get("analysis_type", "general")
        context = self._get_context_from_dependencies(step.depends_on)
        
        if not context:
            docs = self.rag_service.retrieve_context(
                case_id=self.case_id,
                query=step.query or step.instruction,
                k=50,
                db=self.db
            )
            context = "\n".join([d.page_content for d in docs])[:8000]
        
        prompt = f"""–ü—Ä–æ–≤–µ–¥–∏ –∞–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞: {analysis_type}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {step.instruction}

–î–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑."""

        response = self.llm.invoke([
            SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–≤–æ–¥–∏—à—å –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑."),
            HumanMessage(content=prompt)
        ])
        
        return StepResult(
            step_id=step.step_id,
            success=True,
            content=response.content if hasattr(response, 'content') else str(response)
        )
    
    async def _execute_compare(self, step: PlanStep) -> StepResult:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ"""
        from langchain_core.messages import HumanMessage, SystemMessage
        
        context = self._get_context_from_dependencies(step.depends_on)
        
        if not context:
            docs = self.rag_service.retrieve_context(
                case_id=self.case_id,
                query=step.query or step.instruction,
                k=50,
                db=self.db
            )
            context = "\n".join([d.page_content for d in docs])[:8000]
        
        prompt = f"""–ü—Ä–æ–≤–µ–¥–∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {step.instruction}

–ü—Ä–µ–¥—Å—Ç–∞–≤—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""

        response = self.llm.invoke([
            SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."),
            HumanMessage(content=prompt)
        ])
        
        return StepResult(
            step_id=step.step_id,
            success=True,
            content=response.content if hasattr(response, 'content') else str(response)
        )
    
    async def _execute_generate(self, step: PlanStep) -> StepResult:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç"""
        from langchain_core.messages import HumanMessage, SystemMessage
        
        context = self._get_context_from_dependencies(step.depends_on)
        output_type = step.params.get("output_type", "text")
        
        prompt = f"""–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–µ–∫—Å—Ç —Ç–∏–ø–∞: {output_type}

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –¥–∞–Ω–Ω—ã–µ:
{context}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {step.instruction}"""

        response = self.llm.invoke([
            SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å. –°–æ–∑–¥–∞—ë—à—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã."),
            HumanMessage(content=prompt)
        ])
        
        return StepResult(
            step_id=step.step_id,
            success=True,
            content=response.content if hasattr(response, 'content') else str(response)
        )
    
    async def _execute_legal_research(self, step: PlanStep) -> StepResult:
        """–ü–æ–∏—Å–∫ –≤ –ø—Ä–∞–≤–æ–≤—ã—Ö –±–∞–∑–∞—Ö (–ì–ê–†–ê–ù–¢)"""
        if not self.legal_research:
            return StepResult(
                step_id=step.step_id,
                success=False,
                content="–ü–æ–∏—Å–∫ –≤ –ì–ê–†–ê–ù–¢ –æ—Ç–∫–ª—é—á—ë–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"
            )
        
        try:
            from app.services.langchain_agents.garant_tools import search_garant
            
            query = step.query or step.instruction
            result = search_garant.invoke({"query": query})
            
            return StepResult(
                step_id=step.step_id,
                success=True,
                content=result,
                sources=["–ì–ê–†–ê–ù–¢"]
            )
        except Exception as e:
            logger.warning(f"[AutonomousAgent] GARANT search failed: {e}")
            return StepResult(
                step_id=step.step_id,
                success=False,
                content=f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –ì–ê–†–ê–ù–¢: {str(e)}"
            )
    
    async def _execute_web_search(self, step: PlanStep) -> StepResult:
        """–í–µ–±-–ø–æ–∏—Å–∫"""
        if not self.web_search:
            return StepResult(
                step_id=step.step_id,
                success=False,
                content="–í–µ–±-–ø–æ–∏—Å–∫ –æ—Ç–∫–ª—é—á—ë–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"
            )
        
        try:
            from app.services.langchain_agents.web_research_tool import web_research_tool
            
            query = step.query or step.instruction
            result = web_research_tool.invoke({"query": query})
            
            return StepResult(
                step_id=step.step_id,
                success=True,
                content=result,
                sources=["Web"]
            )
        except Exception as e:
            logger.warning(f"[AutonomousAgent] Web search failed: {e}")
            return StepResult(
                step_id=step.step_id,
                success=False,
                content=f"–û—à–∏–±–∫–∞ –≤–µ–±-–ø–æ–∏—Å–∫–∞: {str(e)}"
            )
    
    async def _execute_custom(self, step: PlanStep) -> StepResult:
        """–ö–∞—Å—Ç–æ–º–Ω—ã–π LLM-–∑–∞–ø—Ä–æ—Å"""
        from langchain_core.messages import HumanMessage, SystemMessage
        
        context = self._get_context_from_dependencies(step.depends_on)
        
        if not context and step.query:
            docs = self.rag_service.retrieve_context(
                case_id=self.case_id,
                query=step.query,
                k=30,
                db=self.db
            )
            context = "\n".join([d.page_content for d in docs])[:6000]
        
        prompt = f"""–í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞—á—É:

{step.instruction}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context if context else '–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω'}"""

        response = self.llm.invoke([
            SystemMessage(content="–¢—ã —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –í—ã–ø–æ–ª–Ω—è–π –∑–∞–¥–∞—á–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ."),
            HumanMessage(content=prompt)
        ])
        
        return StepResult(
            step_id=step.step_id,
            success=True,
            content=response.content if hasattr(response, 'content') else str(response)
        )
    
    def _get_context_from_dependencies(self, depends_on: List[int]) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–≤–∏—Å–∏–º—ã—Ö —à–∞–≥–æ–≤"""
        if not depends_on:
            return ""
        
        contexts = []
        for dep_id in depends_on:
            if dep_id in self.step_results:
                result = self.step_results[dep_id]
                if result.success and result.content:
                    contexts.append(result.content)
        
        return "\n\n---\n\n".join(contexts)
    
    # =========================================================================
    # –§–ê–ó–ê 4: –°–ò–ù–¢–ï–ó
    # =========================================================================
    
    async def _synthesize_answer(self, question: str, plan: ExecutionPlan) -> str:
        """
        –°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—Å–µ—Ö —à–∞–≥–æ–≤.
        """
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_results = []
        all_sources = set()
        
        for step_id, result in self.step_results.items():
            if result.success and result.content:
                all_results.append(f"### –†–µ–∑—É–ª—å—Ç–∞—Ç —à–∞–≥–∞ {step_id}:\n{result.content}")
                all_sources.update(result.sources)
        
        combined_results = "\n\n".join(all_results)
        
        prompt = f"""–°–∏–Ω—Ç–µ–∑–∏—Ä—É–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–í–û–ü–†–û–°: {question}

–ü–û–ù–ò–ú–ê–ù–ò–ï –ó–ê–î–ê–ß–ò: {plan.task_understanding}

–û–ñ–ò–î–ê–ï–ú–´–ô –§–û–†–ú–ê–¢: {plan.expected_output}

–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê:
{combined_results}

–ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ü–û–õ–ù–´–ú –∏ –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ú
2. –ò—Å–ø–æ–ª—å–∑—É–π Markdown –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
3. –£–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
4. –ï—Å–ª–∏ –±—ã–ª–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –∏–ª–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ ‚Äî –æ—Ç–º–µ—Ç—å –∏—Ö
5. –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ

–ò–°–¢–û–ß–ù–ò–ö–ò: {', '.join(all_sources) if all_sources else '–¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–µ–ª–∞'}

–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç:"""

        response = self.llm.invoke([
            SystemMessage(content="–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —ç–∫—Å–ø–µ—Ä—Ç. –î–∞—ë—à—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã."),
            HumanMessage(content=prompt)
        ])
        
        answer = response.content if hasattr(response, 'content') else str(response)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if all_sources:
            answer += f"\n\n---\nüìö *–ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(all_sources)}*"
        
        return answer

