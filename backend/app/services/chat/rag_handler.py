"""
RAG Handler - –û–±—Ä–∞–±–æ—Ç—á–∏–∫ RAG-–∑–∞–ø—Ä–æ—Å–æ–≤

–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞:
- –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤ —Å —Ü–∏—Ç–∞—Ç–∞–º–∏
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –ì–ê–†–ê–ù–¢
- Thinking (–ø–æ—à–∞–≥–æ–≤–æ–µ –º—ã—à–ª–µ–Ω–∏–µ)

Production features:
- Circuit Breaker –¥–ª—è –ì–ê–†–ê–ù–¢
- Retry –¥–ª—è LLM –≤—ã–∑–æ–≤–æ–≤
- Graceful degradation
"""
from typing import AsyncGenerator, List, Dict, Any, Optional
from sqlalchemy.orm import Session
import logging
import re

from app.services.chat.events import (
    SSEEvent,
    TextDeltaEvent,
    CitationsEvent,
    ReasoningEvent,
    ErrorEvent,
    Citation,
    SSESerializer,
)
from app.services.chat.metrics import get_metrics, MetricTimer
from app.services.rag_service import RAGService
from app.models.user import User
from app.core.resilience import (
    CircuitBreakerRegistry,
    CircuitBreakerError,
    EXTERNAL_API_CIRCUIT_CONFIG,
    retry,
    RetryConfig,
    with_timeout,
)

logger = logging.getLogger(__name__)

# Circuit breakers –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
garant_circuit = CircuitBreakerRegistry.get("garant", EXTERNAL_API_CIRCUIT_CONFIG)


class RAGHandler:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ RAG-–∑–∞–ø—Ä–æ—Å–æ–≤.
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç:
    1. –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ RAG
    2. –ü–æ–∏—Å–∫ –≤ –ì–ê–†–ê–ù–¢ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    3. Thinking (–ø–æ—à–∞–≥–æ–≤–æ–µ –º—ã—à–ª–µ–Ω–∏–µ)
    4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å citations
    """
    
    def __init__(
        self,
        rag_service: RAGService,
        db: Session
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
        
        Args:
            rag_service: RAG —Å–µ—Ä–≤–∏—Å
            db: SQLAlchemy —Å–µ—Å—Å–∏—è
        """
        self.rag_service = rag_service
        self.db = db
        self.metrics = get_metrics()
    
    async def handle(
        self,
        case_id: str,
        question: str,
        current_user: User,
        chat_history: Optional[List[Dict[str, str]]] = None,
        legal_research: bool = False,
        deep_think: bool = False,
        web_search: bool = False
    ) -> AsyncGenerator[str, None]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å RAG-–∑–∞–ø—Ä–æ—Å
        
        Args:
            case_id: ID –¥–µ–ª–∞
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            current_user: –¢–µ–∫—É—â–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            chat_history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
            legal_research: –í–∫–ª—é—á–∏—Ç—å –ø–æ–∏—Å–∫ –≤ –ì–ê–†–ê–ù–¢
            deep_think: –í–∫–ª—é—á–∏—Ç—å –≥–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ
            web_search: –í–∫–ª—é—á–∏—Ç—å –≤–µ–±-–ø–æ–∏—Å–∫
            
        Yields:
            SSE —Å–æ–±—ã—Ç–∏—è (—Å—Ç—Ä–æ–∫–∏)
        """
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–µ–ª–∞
            rag_docs = []
            rag_context = ""
            try:
                rag_docs = self.rag_service.retrieve_context(
                    case_id=case_id,
                    query=question,
                    k=5,
                    retrieval_strategy="multi_query",
                    db=self.db
                )
                if rag_docs:
                    rag_context = self.rag_service.format_sources_for_prompt(rag_docs, max_context_chars=4000)
                    logger.info(f"[RAGHandler] Retrieved {len(rag_docs)} docs for context")
            except Exception as e:
                logger.warning(f"[RAGHandler] RAG retrieval failed: {e}")
            
            # 2. –ü–æ–∏—Å–∫ –≤ –ì–ê–†–ê–ù–¢ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
            garant_context = ""
            garant_citations = []
            if legal_research:
                garant_context, garant_citations = await self._search_garant(question)
            
            # 3. Thinking (–ø–æ—à–∞–≥–æ–≤–æ–µ –º—ã—à–ª–µ–Ω–∏–µ)
            thinking_context = rag_context
            if garant_context:
                thinking_context += f"\n{garant_context}"
            
            async for event in self._run_thinking(question, thinking_context, deep_think):
                yield event
            
            # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            async for event in self._generate_response(
                question=question,
                rag_docs=rag_docs,
                rag_context=rag_context,
                garant_context=garant_context,
                garant_citations=garant_citations,
                chat_history=chat_history,
                deep_think=deep_think,
                legal_research=legal_research
            ):
                yield event
                
        except Exception as e:
            logger.error(f"[RAGHandler] Error: {e}", exc_info=True)
            yield SSESerializer.error(str(e))
    
    async def _search_garant(self, question: str) -> tuple[str, List[Dict[str, Any]]]:
        """
        –ü–æ–∏—Å–∫ –≤ –ì–ê–†–ê–ù–¢ —Å Circuit Breaker
        
        Returns:
            (garant_context, garant_citations)
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º Circuit Breaker
            if not garant_circuit.can_execute():
                logger.warning("[RAGHandler] –ì–ê–†–ê–ù–¢ circuit breaker is OPEN, skipping")
                self.metrics.record_external_call("garant", success=False, reason="circuit_open")
                return "", []
            
            logger.info(f"[RAGHandler] Searching –ì–ê–†–ê–ù–¢ for: {question[:100]}‚Ä¶")
            from app.services.langchain_agents.utils import get_garant_source
            
            garant_source = get_garant_source()
            if not garant_source or not garant_source.api_key:
                logger.warning("[RAGHandler] –ì–ê–†–ê–ù–¢ source not available")
                return "", []
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å Circuit Breaker
            async with garant_circuit:
                results = await garant_source.search(query=question, max_results=10)
            
            self.metrics.record_external_call("garant", success=True)
            
            if not results:
                logger.warning("[RAGHandler] –ì–ê–†–ê–ù–¢ returned no results")
                return "", []
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            formatted_parts = []
            citations = []
            
            for i, result in enumerate(results, 1):
                title = result.title or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
                url = result.url or ""
                content = result.content[:1500] if result.content else ""
                
                metadata = getattr(result, 'metadata', {}) or {}
                doc_type = metadata.get('doc_type', '')
                doc_date = metadata.get('doc_date', '')
                doc_number = metadata.get('doc_number', '')
                doc_id = metadata.get('doc_id', '') or metadata.get('topic', '')
                
                formatted_parts.append(f"\n{'='*60}")
                formatted_parts.append(f"–î–û–ö–£–ú–ï–ù–¢ {i} –ò–ó –ì–ê–†–ê–ù–¢")
                formatted_parts.append(f"{'='*60}")
                formatted_parts.append(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {title}")
                
                if doc_type:
                    formatted_parts.append(f"–¢–∏–ø: {doc_type}")
                if doc_date:
                    formatted_parts.append(f"–î–∞—Ç–∞: {doc_date}")
                if doc_number:
                    formatted_parts.append(f"–ù–æ–º–µ—Ä: {doc_number}")
                if url:
                    formatted_parts.append(f"–°—Å—ã–ª–∫–∞: {url}")
                
                if content:
                    formatted_parts.append(f"\n–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\n{content}")
                    if result.content and len(result.content) > 1500:
                        formatted_parts.append(f"\n[‚Ä¶ –¥–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–µ–∑–∞–Ω ‚Ä¶]")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è citations
                citations.append({
                    "source_id": f"garant_{doc_id or i}",
                    "file_name": title,
                    "page": None,
                    "quote": content[:500] if content else title,
                    "char_start": None,
                    "char_end": None,
                    "url": url,
                    "source_type": "garant",
                    "doc_type": doc_type,
                    "doc_date": doc_date,
                    "doc_number": doc_number
                })
            
            garant_context = f"\n\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê –í –ì–ê–†–ê–ù–¢ ===\n" + "\n".join(formatted_parts) + "\n=== –ö–û–ù–ï–¶ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ì–ê–†–ê–ù–¢ ===\n"
            logger.info(f"[RAGHandler] –ì–ê–†–ê–ù–¢: {len(results)} results, {len(citations)} citations")
            
            return garant_context, citations
            
        except CircuitBreakerError as e:
            logger.warning(f"[RAGHandler] –ì–ê–†–ê–ù–¢ circuit breaker triggered: {e}")
            self.metrics.record_external_call("garant", success=False, reason="circuit_breaker")
            return "", []
        except Exception as e:
            logger.error(f"[RAGHandler] –ì–ê–†–ê–ù–¢ search error: {e}", exc_info=True)
            self.metrics.record_external_call("garant", success=False, reason="error")
            return "", []
    
    async def _run_thinking(
        self,
        question: str,
        context: str,
        deep_think: bool
    ) -> AsyncGenerator[str, None]:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å thinking (–ø–æ—à–∞–≥–æ–≤–æ–µ –º—ã—à–ª–µ–Ω–∏–µ)
        
        Yields:
            SSE —Å–æ–±—ã—Ç–∏—è reasoning
        """
        try:
            from app.services.thinking_service import get_thinking_service
            
            thinking_service = get_thinking_service(deep_think=deep_think)
            mode = "DEEP THINK" if deep_think else "standard"
            logger.info(f"[RAGHandler] Starting {mode} thinking")
            
            async for step in thinking_service.think(
                question=question,
                context=context,
                stream_steps=True
            ):
                yield SSESerializer.reasoning(
                    phase=step.phase.value,
                    step=step.step_number,
                    total_steps=step.total_steps,
                    content=step.content
                )
                logger.debug(f"[RAGHandler] Thinking step {step.step_number}/{step.total_steps}")
                
        except Exception as e:
            logger.warning(f"[RAGHandler] Thinking error: {e}, continuing without thinking")
    
    async def _generate_response(
        self,
        question: str,
        rag_docs: List,
        rag_context: str,
        garant_context: str,
        garant_citations: List[Dict[str, Any]],
        chat_history: Optional[List[Dict[str, str]]],
        deep_think: bool,
        legal_research: bool
    ) -> AsyncGenerator[str, None]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        
        Yields:
            SSE —Å–æ–±—ã—Ç–∏—è (text_delta, citations)
        """
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ citations
        all_citations = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ì–ê–†–ê–ù–¢ citations
        if garant_citations:
            all_citations.extend(garant_citations)
        
        # –ü—Ä–æ–±—É–µ–º structured citations
        structured_result = None
        if rag_docs and not legal_research:
            try:
                structured_result = self.rag_service.generate_with_structured_citations(
                    query=question,
                    documents=rag_docs,
                    history=chat_history
                )
                
                if structured_result and structured_result.citations:
                    for citation in structured_result.citations:
                        all_citations.append({
                            "source_id": citation.source_id,
                            "file_name": citation.file_name,
                            "page": citation.page,
                            "quote": citation.quote,
                            "char_start": citation.char_start,
                            "char_end": citation.char_end,
                            "source_type": "document"
                        })
            except Exception as e:
                logger.warning(f"[RAGHandler] Structured citations failed: {e}")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å structured result, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if structured_result and structured_result.answer:
            response_text = structured_result.answer
            
            # –î–æ–±–∞–≤–ª—è–µ–º inline citations –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if all_citations and not re.search(r"\[\d+\]", response_text):
                response_text = self._add_inline_citations(response_text, len(all_citations))
            
            # Stream –ø–æ —Å–ª–æ–≤–∞–º
            words = response_text.split(" ")
            for i, word in enumerate(words):
                chunk = word + (" " if i < len(words) - 1 else "")
                yield SSESerializer.text_delta(chunk)
        else:
            # Fallback –Ω–∞ ChatAgent
            async for event in self._fallback_to_chat_agent(
                question=question,
                rag_context=rag_context,
                garant_context=garant_context,
                deep_think=deep_think,
                legal_research=legal_research
            ):
                yield event
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º citations
        if all_citations:
            yield SSESerializer.citations(all_citations)
    
    def _add_inline_citations(self, text: str, num_citations: int) -> str:
        """–î–æ–±–∞–≤–∏—Ç—å inline citations –≤ —Ç–µ–∫—Å—Ç"""
        sentences = re.split(r'(?<=[.!?])\s+', text.strip())
        rebuilt = []
        citation_idx = 0
        
        for sentence in sentences:
            if not sentence.strip():
                continue
            
            if citation_idx < num_citations:
                sentence_stripped = sentence.rstrip()
                if sentence_stripped and sentence_stripped[-1] in '.!?':
                    punct = sentence_stripped[-1]
                    rebuilt.append(f"{sentence_stripped[:-1]}[{citation_idx + 1}]{punct}")
                else:
                    rebuilt.append(f"{sentence}[{citation_idx + 1}]")
                citation_idx += 1
            else:
                rebuilt.append(sentence)
        
        return " ".join(rebuilt)
    
    async def _fallback_to_chat_agent(
        self,
        question: str,
        rag_context: str,
        garant_context: str,
        deep_think: bool,
        legal_research: bool
    ) -> AsyncGenerator[str, None]:
        """
        Fallback –Ω–∞ ChatAgent
        
        Yields:
            SSE —Å–æ–±—ã—Ç–∏—è
        """
        try:
            from app.services.langchain_agents.legacy_stubs import ChatAgent
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º enhanced question
            enhanced_question = question
            
            if deep_think:
                enhanced_question = self._add_deep_think_instructions(enhanced_question)
            
            if garant_context:
                enhanced_question += f"\n\n{garant_context}\n{self._get_garant_instructions()}"
            
            if rag_context:
                enhanced_question += f"\n\n=== –ö–û–ù–¢–ï–ö–°–¢ –ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í –î–ï–õ–ê ===\n{rag_context}\n=== –ö–û–ù–ï–¶ –ö–û–ù–¢–ï–ö–°–¢–ê ===\n"
            
            chat_agent = ChatAgent(
                case_id="",  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é
                rag_service=self.rag_service,
                db=self.db,
                legal_research_enabled=legal_research
            )
            
            async for chunk in chat_agent.answer_stream(enhanced_question):
                if chunk:
                    yield SSESerializer.text_delta(chunk)
                    
        except Exception as e:
            logger.error(f"[RAGHandler] ChatAgent fallback error: {e}", exc_info=True)
            yield SSESerializer.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
    
    def _add_deep_think_instructions(self, question: str) -> str:
        """–î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è deep think"""
        return f"""
=== –†–ï–ñ–ò–ú –ì–õ–£–ë–û–ö–û–ì–û –ú–´–®–õ–ï–ù–ò–Ø (GigaChat Pro) ===
–¢—ã –î–û–õ–ñ–ï–ù –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π, –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç:

1. **–ü—Ä–∞–≤–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑**: –£–∫–∞–∂–∏ –ø—Ä–∏–º–µ–Ω–∏–º—ã–µ –Ω–æ—Ä–º—ã –ø—Ä–∞–≤–∞
2. **–°—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞**: –ü—Ä–∏–≤–µ–¥–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è —Å—É–¥–æ–≤
3. **–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤**: –û—Ü–µ–Ω–∏ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ä–∏—Å–∫–∏
4. **–ö–æ–Ω—Ç—Ä–∞—Ä–≥—É–º–µ–Ω—Ç—ã**: –†–∞—Å—Å–º–æ—Ç—Ä–∏ –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
5. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**: –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç:
üìú **–ü—Ä–∞–≤–æ–≤–∞—è –±–∞–∑–∞**
üèõÔ∏è **–°—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞**
‚öñÔ∏è **–ê–Ω–∞–ª–∏–∑ –ø–æ–∑–∏—Ü–∏–π**
‚ö†Ô∏è **–†–∏—Å–∫–∏**
‚úÖ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**
=== –ö–û–ù–ï–¶ –ò–ù–°–¢–†–£–ö–¶–ò–ò ===

{question}"""
    
    def _get_garant_instructions(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ì–ê–†–ê–ù–¢"""
        return """
=== –ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ì–ê–†–ê–ù–¢ ===
1. –ò—Å–ø–æ–ª—å–∑—É–π –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞
2. –¶–∏—Ç–∏—Ä—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∏ –∑–∞–∫–æ–Ω—ã
3. –£–∫–∞–∑—ã–≤–∞–π —Å—Å—ã–ª–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [–ù–∞–∑–≤–∞–Ω–∏–µ](URL)
4. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –ì–ê–†–ê–ù–¢
=== –ö–û–ù–ï–¶ –ò–ù–°–¢–†–£–ö–¶–ò–ô ==="""


