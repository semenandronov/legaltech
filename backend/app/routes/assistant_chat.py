"""Assistant UI chat endpoint for streaming responses"""
from fastapi import APIRouter, HTTPException, Depends, Request, BackgroundTasks
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from typing import AsyncGenerator, Optional, Literal, List
import hashlib
from app.utils.database import get_db
from app.utils.auth import get_current_user
from app.models.case import Case, File as FileModel, ChatMessage
from app.models.user import User
from app.services.rag_service import RAGService
from app.services.document_processor import DocumentProcessor
from app.services.langchain_memory import MemoryService
from app.services.llm_factory import create_llm, create_legal_llm
# Agents removed - using simple RAG chat only
from app.services.external_sources.web_research_service import get_web_research_service
from app.services.external_sources.source_router import get_source_router, initialize_source_router
from app.services.external_sources.cache_manager import get_cache_manager
from app.services.langchain_agents.pipeline_service import PipelineService
from app.services.langchain_agents.planning_agent import PlanningAgent
from app.services.langchain_agents.advanced_planning_agent import AdvancedPlanningAgent
from app.config import config
import json
import logging
import asyncio
from datetime import datetime

logger = logging.getLogger(__name__)

router = APIRouter()

# Initialize services
rag_service = RAGService()
document_processor = DocumentProcessor()
memory_service = MemoryService()

# Initialize classification cache
_classification_cache = None


def get_classification_cache():
    """Get or create classification cache manager"""
    global _classification_cache
    if _classification_cache is None:
        from app.config import config
        redis_url = getattr(config, 'REDIS_URL', None)
        ttl = getattr(config, 'CACHE_TTL_SECONDS', 3600)
        _classification_cache = get_cache_manager(redis_url=redis_url, default_ttl=ttl)
    return _classification_cache


class AssistantMessage(BaseModel):
    """Message model for assistant-ui"""
    role: str = Field(..., description="Message role: user or assistant")
    content: str = Field(..., description="Message content")


class ClassificationResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    label: Literal["task", "question"] = Field(..., description="–ú–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: task –∏–ª–∏ question")
    confidence: float = Field(..., ge=0.0, le=1.0, description="–£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç 0.0 –¥–æ 1.0")
    rationale: Optional[str] = Field(None, description="–ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")


# Note: Request body is parsed manually to support assistant-ui format
# Assistant-ui sends: { messages: [...], case_id: "..." }


def normalize_text(text: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è: lower, strip, —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        
    Returns:
        –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    return " ".join(text.lower().strip().split())


def make_classification_cache_key(question: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç cache key –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    
    Args:
        question: –í—Ö–æ–¥–Ω–æ–π –≤–æ–ø—Ä–æ—Å
        
    Returns:
        Cache key (—Ö–µ—à –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞)
    """
    normalized = normalize_text(question)
    key_hash = hashlib.sha256(normalized.encode('utf-8')).hexdigest()
    return f"classification:{key_hash}"


async def classify_request(question: str, llm) -> bool:
    """
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –∑–∞–¥–∞—á–µ–π –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤
    –∏–ª–∏ –æ–±—ã—á–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º –¥–ª—è RAG —á–∞—Ç–∞.
    
    Args:
        question: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        llm: LLM –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    
    Returns:
        True –µ—Å–ª–∏ —ç—Ç–æ –∑–∞–¥–∞—á–∞, False –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å
    """
    import re
    
    # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    normalized_question = normalize_text(question)
    question_lower = normalized_question.lower()
    
    # 2. Rule-based –ø—Ä–æ–≤–µ—Ä–∫–∞ (fast path)
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å—Ç–∞—Ç–µ–π –∫–æ–¥–µ–∫—Å–æ–≤ - –≤—Å–µ–≥–¥–∞ QUESTION
    article_patterns = [
        r'—Å—Ç–∞—Ç—å—è\s+\d+\s+(–≥–ø–∫|–≥–∫|–∞–ø–∫|—É–∫|–Ω–∫|—Ç–∫|—Å–∫|–∂–∫|–∑–∫–ø–ø|–∫–∞—Å)',
        r'\d+\s+—Å—Ç–∞—Ç—å—è\s+(–≥–ø–∫|–≥–∫|–∞–ø–∫|—É–∫|–Ω–∫|—Ç–∫|—Å–∫|–∂–∫|–∑–∫–ø–ø|–∫–∞—Å)',
        r'—Å—Ç–∞—Ç—å—è\s+\d+\s+(–≥—Ä–∞–∂–¥–∞–Ω—Å–∫|–∞—Ä–±–∏—Ç—Ä–∞–∂|—É–≥–æ–ª–æ–≤–Ω|–Ω–∞–ª–æ–≥–æ–≤|—Ç—Ä—É–¥–æ–≤|—Å–µ–º–µ–π–Ω|–∂–∏–ª–∏—â–Ω|–∑–µ–º–µ–ª—å–Ω|–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω)',
        r'–ø—Ä–∏—à–ª–∏\s+—Å—Ç–∞—Ç—å—é',
        r'–ø–æ–∫–∞–∂–∏\s+—Å—Ç–∞—Ç—å—é',
        r'–Ω–∞–π–¥–∏\s+—Å—Ç–∞—Ç—å—é',
        r'—Ç–µ–∫—Å—Ç\s+—Å—Ç–∞—Ç—å–∏',
    ]
    
    for pattern in article_patterns:
        if re.search(pattern, question_lower):
            logger.info(f"Pre-classified '{question[:50]}...' as QUESTION (matches article request pattern: {pattern})")
            return False
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π - –≤—Å–µ–≥–¥–∞ QUESTION
    greeting_patterns = [
        r'^(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ|–¥–æ–±—Ä—ã–π\s+(–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ)|hello|hi)',
    ]
    
    for pattern in greeting_patterns:
        if re.search(pattern, question_lower):
            logger.info(f"Pre-classified '{question[:50]}...' as QUESTION (matches greeting pattern: {pattern})")
            return False
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
    cache = get_classification_cache()
    cached_result = cache.get("classification", normalized_question)
    
    if cached_result:
        label = cached_result.get("label", "question")
        cached_confidence = cached_result.get("confidence", 1.0)
        logger.info(f"Cache hit for classification: '{question[:50]}...' -> {label} (confidence: {cached_confidence:.2f})")
        return label == "task"
    
    # 4. LLM –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å structured output
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    from app.services.langchain_agents.planning_tools import AVAILABLE_ANALYSES
    
    agents_list = []
    for agent_name, agent_info in AVAILABLE_ANALYSES.items():
        description = agent_info["description"]
        keywords = ", ".join(agent_info["keywords"][:3])  # –ü–µ—Ä–≤—ã–µ 3 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞
        agents_list.append(f"- {agent_name}: {description} (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords})")
    
    agents_text = "\n".join(agents_list)
    
    # Few-shot –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    few_shot_examples = [
        (HumanMessage(content="–ó–∞–ø—Ä–æ—Å: –ò–∑–≤–ª–µ–∫–∏ –≤—Å–µ –¥–∞—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"), 
         AIMessage(content='{"label": "task", "confidence": 0.95, "rationale": "–¢—Ä–µ–±—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ entity_extraction"}')),
        (HumanMessage(content="–ó–∞–ø—Ä–æ—Å: –ö–∞–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å—Ä–æ–∫–∏ –≤–∞–∂–Ω—ã –≤ —ç—Ç–æ–º –¥–µ–ª–µ?"), 
         AIMessage(content='{"label": "question", "confidence": 0.98, "rationale": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å –¥–ª—è RAG —á–∞—Ç–∞"}')),
        (HumanMessage(content="–ó–∞–ø—Ä–æ—Å: –ü—Ä–∏—à–ª–∏ —Å—Ç–∞—Ç—å—é 135 –ì–ü–ö"), 
         AIMessage(content='{"label": "question", "confidence": 0.99, "rationale": "–ó–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏ –∫–æ–¥–µ–∫—Å–∞"}')),
        (HumanMessage(content="–ó–∞–ø—Ä–æ—Å: –ù–∞–π–¥–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –º–µ–∂–¥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏"), 
         AIMessage(content='{"label": "task", "confidence": 0.92, "rationale": "–¢—Ä–µ–±—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ discrepancy"}')),
        (HumanMessage(content="–ó–∞–ø—Ä–æ—Å: –ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –¥–æ–≥–æ–≤–æ—Ä–µ –æ —Å—Ä–æ–∫–∞—Ö?"), 
         AIMessage(content='{"label": "question", "confidence": 0.96, "rationale": "–í–æ–ø—Ä–æ—Å –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è RAG"}')),
        (HumanMessage(content="–ó–∞–ø—Ä–æ—Å: –°–æ—Å—Ç–∞–≤—å —Ç–∞–±–ª–∏—Ü—É —Å —Å—É–¥—å—è–º–∏ –∏ —Å—É–¥–∞–º–∏"), 
         AIMessage(content='{"label": "task", "confidence": 0.94, "rationale": "–¢—Ä–µ–±—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–æ–≤"}')),
    ]
    
    system_content = f"""–¢—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Å–∏—Å—Ç–µ–º–µ –∞–Ω–∞–ª–∏–∑–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–í —Å–∏—Å—Ç–µ–º–µ –¥–æ—Å—Ç—É–ø–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –∞–≥–µ–Ω—Ç—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á:

{agents_text}

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã:
- document_classifier: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–¥–æ–≥–æ–≤–æ—Ä/–ø–∏—Å—å–º–æ/–ø—Ä–∏–≤–∏–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
- entity_extraction: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π (–∏–º–µ–Ω–∞, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, —Å—É–º–º—ã, –¥–∞—Ç—ã)
- privilege_check: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–≤–∏–ª–µ–≥–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞:

–ó–ê–î–ê–ß–ê (task) - –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤:
- –ó–∞–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ñ—É–Ω–∫—Ü–∏—è–º –∞–≥–µ–Ω—Ç–æ–≤ (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç, –ø–æ–∏—Å–∫ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π, –∞–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤ –∏ —Ç.–¥.)
- –¢—Ä–µ–±—É–µ—Ç –∑–∞–ø—É—Å–∫–∞ —Ñ–æ–Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–æ–≤
- –ù–ï –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–æ—Å—Ç—ã–º –∑–∞–ø—Ä–æ—Å–∞–º –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—Å—Ç–∞—Ç—å–∏ –∫–æ–¥–µ–∫—Å–æ–≤, —Ç–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
- –ü—Ä–∏–º–µ—Ä—ã: "–ò–∑–≤–ª–µ–∫–∏ –≤—Å–µ –¥–∞—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", "–ù–∞–π–¥–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è", "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∏—Å–∫–∏", "–°–æ–∑–¥–∞–π —Ä–µ–∑—é–º–µ –¥–µ–ª–∞", "—Å–æ—Å—Ç–∞–≤—å —Ç–∞–±–ª–∏—Ü—É —Å —Å—É–¥—å—è–º–∏ –∏ —Å—É–¥–∞–º–∏"

–í–û–ü–†–û–° (question) - –µ—Å–ª–∏ —ç—Ç–æ –æ–±—ã—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å –¥–ª—è RAG —á–∞—Ç–∞:
- –í–æ–ø—Ä–æ—Å—ã —Å "–∫–∞–∫–∏–µ", "—á—Ç–æ", "–≥–¥–µ", "–∫–æ–≥–¥–∞", "–∫—Ç–æ", "–ø–æ—á–µ–º—É"
- –†–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã: "–∫–∞–∫ –¥–µ–ª–∞", "–ø—Ä–∏–≤–µ—Ç"
- –ó–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—Å—Ç–∞—Ç—å–∏ –∫–æ–¥–µ–∫—Å–æ–≤, –Ω–æ—Ä–º –ø—Ä–∞–≤–∞, —Ç–µ–∫—Å—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
- –¢—Ä–µ–±—É–µ—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- –ü—Ä–∏–º–µ—Ä—ã: "–ö–∞–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å—Ä–æ–∫–∏ –≤–∞–∂–Ω—ã –≤ —ç—Ç–æ–º –¥–µ–ª–µ?", "–ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –¥–æ–≥–æ–≤–æ—Ä–µ –æ —Å—Ä–æ–∫–∞—Ö?", "–ü—Ä–∏—à–ª–∏ —Å—Ç–∞—Ç—å—é 135 –ì–ü–ö", "–ü–æ–∫–∞–∂–∏ —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ 123 –ì–ö –†–§"

–í–æ–∑–≤—Ä–∞—â–∞–π —Å—Ç—Ä–æ–≥–æ JSON —Å –ø–æ–ª—è–º–∏:
- label: "task" –∏–ª–∏ "question"
- confidence: —á–∏—Å–ª–æ –æ—Ç 0.0 –¥–æ 1.0 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
- rationale: –∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å few-shot –ø—Ä–∏–º–µ—Ä–∞–º–∏
    messages = [SystemMessage(content=system_content)]
    for human_msg, ai_msg in few_shot_examples:
        messages.append(human_msg)
        messages.append(ai_msg)
    messages.append(HumanMessage(content=f"–ó–∞–ø—Ä–æ—Å: {question}"))
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º structured output –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
        if hasattr(llm, 'with_structured_output'):
            try:
                structured_llm = llm.with_structured_output(ClassificationResult, include_raw=True)
                response = structured_llm.invoke(messages)
                
                if hasattr(response, 'parsed') and response.parsed:
                    classification = response.parsed
                elif isinstance(response, dict) and 'parsed' in response:
                    classification = response['parsed']
                elif isinstance(response, ClassificationResult):
                    classification = response
                else:
                    # Fallback: –ø–∞—Ä—Å–∏–º raw –æ—Ç–≤–µ—Ç
                    raw_content = getattr(response, 'raw', None) or (response.get('raw') if isinstance(response, dict) else str(response))
                    logger.warning(f"Structured output parsing failed, using raw response: {raw_content}")
                    raise ValueError("Failed to parse structured output")
                
                label = classification.label
                confidence = classification.confidence
                rationale = classification.rationale or ""
                
            except Exception as structured_error:
                logger.warning(f"Structured output failed: {structured_error}, falling back to JSON parsing")
                # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –≤—ã–∑–æ–≤ –∏ –ø–∞—Ä—Å–∏–Ω–≥ JSON
                response = llm.invoke(messages)
                response_text = response.content if hasattr(response, 'content') else str(response)
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
                import json
                try:
                    # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
                    json_match = re.search(r'\{[^}]+\}', response_text)
                    if json_match:
                        result_dict = json.loads(json_match.group())
                        label = result_dict.get("label", "question")
                        confidence = float(result_dict.get("confidence", 0.5))
                        rationale = result_dict.get("rationale", "")
                    else:
                        raise ValueError("No JSON found in response")
                except Exception as json_error:
                    logger.error(f"JSON parsing failed: {json_error}, response: {response_text}")
                    # –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback: –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                    response_lower = response_text.lower()
                    if "task" in response_lower and response_lower.find("task") < response_lower.find("question", response_lower.find("task")):
                        label = "task"
                        confidence = 0.5
                    else:
                        label = "question"
                        confidence = 0.5
                    rationale = ""
        else:
            # LLM –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç structured output, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –≤—ã–∑–æ–≤
            response = llm.invoke(messages)
            response_text = response.content if hasattr(response, 'content') else str(response)
            
            import json
            try:
                json_match = re.search(r'\{[^}]+\}', response_text)
                if json_match:
                    result_dict = json.loads(json_match.group())
                    label = result_dict.get("label", "question")
                    confidence = float(result_dict.get("confidence", 0.5))
                    rationale = result_dict.get("rationale", "")
                else:
                    raise ValueError("No JSON found in response")
            except Exception:
                response_lower = response_text.lower()
                if "task" in response_lower:
                    label = "task"
                    confidence = 0.5
                else:
                    label = "question"
                    confidence = 0.5
                rationale = ""
        
        # 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ confidence threshold
        if confidence >= 0.85:
            # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –ø—Ä–∏–Ω–∏–º–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            final_label = label
        elif confidence >= 0.6:
            # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –ø—Ä–∏–Ω–∏–º–∞–µ–º, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º
            final_label = label
            logger.info(f"Medium confidence classification: '{question[:50]}...' -> {label} (confidence: {confidence:.2f})")
        else:
            # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - fallback –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω—É—é –º–µ—Ç–∫—É
            final_label = "question"
            logger.warning(f"Low confidence classification for '{question[:50]}...': {label} (confidence: {confidence:.2f}), falling back to 'question'")
            rationale = f"Low confidence ({confidence:.2f}), fallback to question"
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
        cache_data = {
            "label": final_label,
            "confidence": confidence,
            "rationale": rationale
        }
        cache.set("classification", normalized_question, cache_data, ttl=3600)
        
        # 7. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        logger.info(f"Classified '{question[:50]}...' as {final_label.upper()} (confidence: {confidence:.2f}, rationale: {rationale[:50] if rationale else 'N/A'})")
        return final_label == "task"
        
    except Exception as e:
        logger.error(f"Error in LLM classification: {e}", exc_info=True)
        logger.warning("LLM classification failed, defaulting to QUESTION")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É –≤ –∫—ç—à —Å –∫–æ—Ä–æ—Ç–∫–∏–º TTL, —á—Ç–æ–±—ã –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ –≤—ã–∑–æ–≤—ã
        cache_data = {"label": "question", "confidence": 0.5, "rationale": f"Error: {str(e)[:50]}"}
        cache.set("classification", normalized_question, cache_data, ttl=60)
        return False


async def stream_chat_response(
    case_id: str,
    question: str,
    db: Session,
    current_user: User,
    background_tasks: BackgroundTasks,
    web_search: bool = False,
    legal_research: bool = False,
    deep_think: bool = False,
    draft_mode: bool = False,
    document_context: Optional[str] = None,
    document_id: Optional[str] = None,
    selected_text: Optional[str] = None,
    template_file_id: Optional[str] = None,
    template_file_content: Optional[str] = None,
    attached_file_ids: Optional[List[str]] = None
) -> AsyncGenerator[str, None]:
    """
    Stream chat response using RAG and LLM with optional web search and legal research
    
    Yields:
        JSON strings in assistant-ui format
    """
    try:
        # Verify case ownership
        case = db.query(Case).filter(
            Case.id == case_id,
            Case.user_id == current_user.id
        ).first()
        
        if not case:
            yield f"data: {json.dumps({'error': '–î–µ–ª–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'})}\n\n"
            return
        
        # –†–µ–∂–∏–º Draft: —Å–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ –ò–ò
        if draft_mode:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ë–î
            import uuid
            from datetime import datetime, timedelta
            user_message_id = str(uuid.uuid4())
            assistant_message_id = None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º session_id
            session_id = None
            try:
                last_message = db.query(ChatMessage).filter(
                    ChatMessage.case_id == case_id,
                    ChatMessage.content.isnot(None),
                    ChatMessage.content != ""
                ).order_by(ChatMessage.created_at.desc()).first()
                
                if last_message and last_message.created_at:
                    time_diff = datetime.utcnow() - last_message.created_at
                    if time_diff < timedelta(minutes=30) and last_message.session_id:
                        session_id = last_message.session_id
                    else:
                        session_id = str(uuid.uuid4())
                else:
                    session_id = str(uuid.uuid4())
            except Exception as session_error:
                logger.warning(f"Error determining session_id: {session_error}, creating new session")
                session_id = str(uuid.uuid4())
            
            try:
                user_message = ChatMessage(
                    id=user_message_id,
                    case_id=case_id,
                    role="user",
                    content=question,
                    session_id=session_id
                )
                db.add(user_message)
                
                assistant_message_id = str(uuid.uuid4())
                assistant_message_placeholder = ChatMessage(
                    id=assistant_message_id,
                    case_id=case_id,
                    role="assistant",
                    content="",
                    source_references=None,
                    session_id=session_id
                )
                db.add(assistant_message_placeholder)
                db.commit()
                logger.info(f"[Draft Mode] Messages saved to DB, session: {session_id}")
            except Exception as save_error:
                db.rollback()
                logger.warning(f"[Draft Mode] Error saving messages to DB: {save_error}")
            
            try:
                from app.services.langchain_agents.template_graph import create_template_graph
                from app.services.langchain_agents.template_state import TemplateState
                from app.services.document_editor_service import DocumentEditorService
                from app.services.llm_factory import create_legal_llm
                from langchain_core.messages import HumanMessage
                
                logger.info(f"[Draft Mode] Creating document for case {case_id} based on: {question[:100]}...")
                logger.info(f"[Draft Mode] Template file ID: {template_file_id}, Template file content length: {len(template_file_content) if template_file_content else 0}")
                
                # –ò–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
                try:
                    llm = create_legal_llm(temperature=0.1)
                    title_prompt = f"–ò–∑–≤–ª–µ–∫–∏ –∫—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–º–∞–∫—Å–∏–º—É–º 5-7 —Å–ª–æ–≤) –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è: {question}. –û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ–º, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤."
                    title_response = llm.invoke([HumanMessage(content=title_prompt)])
                    title_text = title_response.content if hasattr(title_response, 'content') else str(title_response)
                    document_title = title_text.strip().replace('"', '').replace("'", "").strip()[:255]
                    
                    if not document_title or len(document_title) < 3:
                        document_title = "–ù–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç"
                    if len(document_title) > 255:
                        document_title = document_title[:252] + "..."
                except Exception as title_error:
                    logger.warning(f"[Draft Mode] Error generating title: {title_error}")
                    document_title = "–ù–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç"
                
                # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —à–∞–±–ª–æ–Ω–∞–º–∏
                graph = create_template_graph(db)
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –≥—Ä–∞—Ñ–∞
                initial_state: TemplateState = {
                    "user_query": question,
                    "case_id": case_id,
                    "user_id": current_user.id,
                    "cached_template": None,
                    "garant_template": None,
                    "template_source": None,
                    "final_template": None,
                    "adapted_content": None,
                    "document_id": None,
                    "messages": [],
                    "errors": [],
                    "metadata": {},
                    "should_adapt": True,  # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω –ø–æ–¥ –∑–∞–ø—Ä–æ—Å
                    "document_title": document_title,
                    "template_file_id": template_file_id,  # ID —Ñ–∞–π–ª–∞-—à–∞–±–ª–æ–Ω–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∏–∑ –ë–î)
                    "template_file_content": template_file_content,  # HTML –∫–æ–Ω—Ç–µ–Ω—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–ª–∏ None
                    "case_context": None  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ get_case_context_node
                }
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –≥—Ä–∞—Ñ
                logger.info("[Draft Mode] Running template graph...")
                result = await graph.ainvoke(initial_state)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ (–µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ —Å–æ–∑–¥–∞–Ω)
                if not result.get("document_id"):
                    if result.get("errors"):
                        error_msg = "; ".join(result["errors"])
                        logger.error(f"[Draft Mode] Template graph errors: {error_msg}")
                        raise Exception(error_msg)
                    else:
                        raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç")
                
                # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω, –Ω–æ –µ—Å—Ç—å –Ω–µ–∫—Ä–∏—Ç–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω) - –ª–æ–≥–∏—Ä—É–µ–º, –Ω–æ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º
                if result.get("errors"):
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∫—Ä–∏—Ç–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ (–æ—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –≤—Å–µ —Ä–∞–≤–Ω–æ —Å–æ–∑–¥–∞–Ω)
                    critical_errors = [
                        err for err in result["errors"] 
                        if "–ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞" in err or 
                           "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞" in err
                    ]
                    if critical_errors:
                        error_msg = "; ".join(critical_errors)
                        logger.error(f"[Draft Mode] Critical template graph errors: {error_msg}")
                        raise Exception(error_msg)
                    else:
                        # –ù–µ–∫—Ä–∏—Ç–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω —Å –Ω—É–ª—è)
                        warning_msg = "; ".join(result["errors"])
                        logger.warning(f"[Draft Mode] Non-critical template graph warnings: {warning_msg}")
                
                # –ü–æ–ª—É—á–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
                doc_service = DocumentEditorService(db)
                document = doc_service.get_document(result["document_id"], current_user.id)
                
                if not document:
                    raise Exception("–°–æ–∑–¥–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
                
                logger.info(f"[Draft Mode] Document created successfully: {document.id} (source: {result.get('template_source', 'unknown')})")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –ë–î
                response_text = f'‚úÖ –î–æ–∫—É–º–µ–Ω—Ç "{document.title}" —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω! –í—ã –º–æ–∂–µ—Ç–µ –æ—Ç–∫—Ä—ã—Ç—å –µ–≥–æ –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.'
                try:
                    if assistant_message_id:
                        assistant_message = db.query(ChatMessage).filter(
                            ChatMessage.id == assistant_message_id
                        ).first()
                        if assistant_message:
                            assistant_message.content = response_text
                            db.commit()
                            logger.info(f"[Draft Mode] Response saved to DB")
                except Exception as save_error:
                    db.rollback()
                    logger.warning(f"[Draft Mode] Failed to save response: {save_error}")
                
                # –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ SSE stream
                yield f"data: {json.dumps({
                    'type': 'document_created',
                    'document': {
                        'id': document.id,
                        'title': document.title,
                        'content': document.content[:500] if document.content else '',  # –ü—Ä–µ–≤—å—é
                        'case_id': document.case_id
                    }
                }, ensure_ascii=False)}\n\n"
                
                # –¢–∞–∫–∂–µ –æ—Ç–ø—Ä–∞–≤–∏–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                yield f"data: {json.dumps({
                    'textDelta': response_text
                }, ensure_ascii=False)}\n\n"
                
                return
                
            except Exception as draft_error:
                logger.error(f"[Draft Mode] Error creating document: {draft_error}", exc_info=True)
                yield f"data: {json.dumps({
                    'textDelta': f'\n\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(draft_error)}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ–ø–∏—à–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ.'
                }, ensure_ascii=False)}\n\n"
                return
        
        # Verify case has files uploaded (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞, –Ω–µ –¥–ª—è draft)
        file_count = db.query(FileModel).filter(FileModel.case_id == case_id).count()
        if file_count == 0:
            yield f"data: {json.dumps({'error': '–í –¥–µ–ª–µ –Ω–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.'})}\n\n"
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ë–î
        import uuid
        from datetime import datetime, timedelta
        user_message_id = str(uuid.uuid4())
        assistant_message_id = None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º session_id: –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–¥–∞–≤–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–≤ —Ç–µ—á–µ–Ω–∏–µ 30 –º–∏–Ω—É—Ç), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö session_id
        # –ò–Ω–∞—á–µ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
        session_id = None
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —ç—Ç–æ–≥–æ –¥–µ–ª–∞
            last_message = db.query(ChatMessage).filter(
                ChatMessage.case_id == case_id,
                ChatMessage.content.isnot(None),
                ChatMessage.content != ""
            ).order_by(ChatMessage.created_at.desc()).first()
            
            if last_message and last_message.created_at:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–æ –ª–∏ –º–µ–Ω–µ–µ 30 –º–∏–Ω—É—Ç —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                time_diff = datetime.utcnow() - last_message.created_at
                if time_diff < timedelta(minutes=30) and last_message.session_id:
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ç–µ–∫—É—â—É—é —Å–µ—Å—Å–∏—é
                    session_id = last_message.session_id
                    logger.info(f"Continuing existing session {session_id} for case {case_id}")
                else:
                    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
                    session_id = str(uuid.uuid4())
                    logger.info(f"Creating new session {session_id} for case {case_id}")
            else:
                # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –¥–µ–ª–µ - —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
                session_id = str(uuid.uuid4())
                logger.info(f"Creating first session {session_id} for case {case_id}")
        except Exception as session_error:
            logger.warning(f"Error determining session_id: {session_error}, creating new session")
            session_id = str(uuid.uuid4())
        
        try:
            user_message = ChatMessage(
                id=user_message_id,
                case_id=case_id,
                role="user",
                content=question,
                session_id=session_id
            )
            db.add(user_message)
            
            # –°–æ–∑–¥–∞—ë–º placeholder –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –î–û streaming
            # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ—Å–ª–µ streaming
            assistant_message_id = str(uuid.uuid4())
            assistant_message_placeholder = ChatMessage(
                id=assistant_message_id,
                case_id=case_id,
                role="assistant",
                content="",  # –ü—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç, –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—ë–Ω –ø–æ—Å–ª–µ streaming
                source_references=None,
                session_id=session_id
            )
            db.add(assistant_message_placeholder)
            db.commit()
            logger.info(f"User message saved to DB with id: {user_message_id}, assistant placeholder: {assistant_message_id}, session: {session_id}")
        except Exception as save_error:
            db.rollback()
            logger.error(f"Error saving messages to DB: {save_error}", exc_info=True)
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è - –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        full_response_text = ""
        sources_list = []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ RAG - —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ PipelineService
        logger.info(f"Processing RAG query for case {case_id}: {question[:100]}...")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if attached_file_ids:
            logger.info(f"Attached file IDs for this query: {attached_file_ids}")
            # –§–∞–π–ª—ã —É–∂–µ –≤ –±–∞–∑–µ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ RAG –ø–æ case_id
            # RAG –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ—Ç –∏—Ö –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–æ case_id
        
        # asyncio —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≥–ª–æ–±–∞–ª—å–Ω–æ
        loop = asyncio.get_event_loop()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - –¢–û–õ–¨–ö–û –∏–∑ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
        chat_history = []
        try:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ session_id, —á—Ç–æ–±—ã –ò–ò –≤–∏–¥–µ–ª —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–∏–π —á–∞—Ç, –∞ –Ω–µ –≤—Å–µ —á–∞—Ç—ã –≤ –¥–µ–ª–µ
            history_query = db.query(ChatMessage).filter(
                ChatMessage.case_id == case_id,
                ChatMessage.content.isnot(None),
                ChatMessage.content != ""
            )
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å session_id, –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
            if session_id:
                history_query = history_query.filter(ChatMessage.session_id == session_id)
            
            history_messages = history_query.order_by(ChatMessage.created_at.desc()).limit(10).all()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ (–æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º)
            chat_history = []
            for msg in reversed(history_messages):
                if msg.role == "user" and msg.content:
                    chat_history.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {msg.content}")
                elif msg.role == "assistant" and msg.content:
                    chat_history.append(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {msg.content[:500]}...")  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            
            if chat_history:
                logger.info(f"Loaded {len(chat_history)} previous messages for context from session {session_id}")
            else:
                logger.info(f"No previous messages found for context in session {session_id}")
        except Exception as history_error:
            logger.warning(f"Failed to load chat history: {history_error}, continuing without history")
            # Continue without history - –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞
        
        # Web search integration - –≤—ã–ø–æ–ª–Ω—è–µ–º –ü–ï–†–í–´–ú, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
        web_search_context = ""
        web_search_successful = False
        
        if web_search:
            try:
                logger.info(f"Web search enabled for query: {question[:100]}...")
                web_research_service = get_web_research_service()
                research_result = await web_research_service.research(
                    query=question,
                    max_results=5,
                    use_cache=True,
                    validate_sources=True
                )
                
                if research_result.sources:
                    web_search_parts = []
                    web_search_parts.append(f"\n\n=== –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–±-–ø–æ–∏—Å–∫–∞ ===")
                    web_search_parts.append(f"–ù–∞–π–¥–µ–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(research_result.sources)}")
                    
                    for i, source in enumerate(research_result.sources[:5], 1):
                        title = source.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
                        url = source.get("url", "")
                        content = source.get("content", "")
                        if content:
                            web_search_parts.append(f"\n[–ò—Å—Ç–æ—á–Ω–∏–∫ {i}: {title}]")
                            if url:
                                web_search_parts.append(f"URL: {url}")
                            web_search_parts.append(f"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {content[:300]}...")
                    
                    web_search_context = "\n".join(web_search_parts)
                    web_search_successful = True
                    logger.info(f"Web search completed: {len(research_result.sources)} sources found")
                else:
                    logger.warning("Web search returned no results")
            except Exception as web_search_error:
                logger.warning(f"Web search failed: {web_search_error}, continuing without web search")
                # Continue without web search - –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞
        
        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω legal_research (–ì–ê–†–ê–ù–¢), —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ –ì–ê–†–ê–ù–¢
        # –í–ê–ñ–ù–û: GigaChat SDK –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç functions/tools, –ø–æ—ç—Ç–æ–º—É
        # –≤—ã–∑—ã–≤–∞–µ–º –ì–ê–†–ê–ù–¢ –Ω–∞–ø—Ä—è–º—É—é –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        garant_context = ""
        if legal_research:
            try:
                logger.info(f"[–ì–ê–†–ê–ù–¢] Legal research enabled, searching in –ì–ê–†–ê–ù–¢ for: {question[:100]}...")
                from app.services.langchain_agents.garant_tools import _garant_search_sync
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –≤ –ì–ê–†–ê–ù–¢
                garant_results = _garant_search_sync(query=question, doc_type="all", max_results=5)
                
                if garant_results and not garant_results.startswith("–û—à–∏–±–∫–∞") and not garant_results.startswith("–ù–µ –Ω–∞–π–¥–µ–Ω–æ"):
                    garant_context = f"\n\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê –í –ì–ê–†–ê–ù–¢ ===\n{garant_results}\n=== –ö–û–ù–ï–¶ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ì–ê–†–ê–ù–¢ ===\n"
                    logger.info(f"[–ì–ê–†–ê–ù–¢] Found results, context length: {len(garant_context)} chars")
                else:
                    logger.warning(f"[–ì–ê–†–ê–ù–¢] No results or error: {garant_results[:200] if garant_results else 'empty'}")
            except Exception as garant_error:
                logger.error(f"[–ì–ê–†–ê–ù–¢] Error searching in –ì–ê–†–ê–ù–¢: {garant_error}", exc_info=True)
        
        # –ü–æ–¥–º–µ—à–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–µ–ª–∞ (RAG) –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –¥–µ–ª—É
        rag_context = ""
        try:
            # –ë–µ—Ä–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –≤–æ–ø—Ä–æ—Å—É
            rag_docs = rag_service.retrieve_context(
                case_id=case_id,
                query=question,
                k=5,
                retrieval_strategy="multi_query",
                db=db
            )
            if rag_docs:
                rag_context = rag_service.format_sources_for_prompt(rag_docs, max_context_chars=4000)
                logger.info(f"[RAG] Added {len(rag_docs)} docs to context (len={len(rag_context)})")
        except Exception as rag_error:
            logger.warning(f"[RAG] Failed to load context: {rag_error}")
        
        # –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω–æ–≥–æ ChatAgent
        # –ü–µ—Ä–µ–¥–∞–µ–º legal_research –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è tools –ì–ê–†–ê–ù–¢ + –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ì–ê–†–ê–ù–¢ –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        from app.services.langchain_agents.chat_agent import ChatAgent
        
        logger.info(f"[ChatAgent] Initializing ChatAgent for question: {question[:100]}... (legal_research={legal_research})")
        chat_agent = ChatAgent(
            case_id=case_id,
            rag_service=rag_service,
            db=db,
            legal_research_enabled=legal_research  # –í–∫–ª—é—á–∞–µ–º tools –ì–ê–†–ê–ù–¢ –µ—Å–ª–∏ legal_research=True
        )
        logger.info(f"[ChatAgent] ChatAgent initialized successfully, legal_research_enabled={legal_research}")
        
        logger.info("[ChatAgent] Using ChatAgent with tools and –ì–ê–†–ê–ù–¢ context injection")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ –∏ –ì–ê–†–ê–ù–¢ –≤ –≤–æ–ø—Ä–æ—Å
        enhanced_question = question
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if deep_think:
            deep_think_instruction = """

=== –†–ï–ñ–ò–ú –ì–õ–£–ë–û–ö–û–ì–û –ú–´–®–õ–ï–ù–ò–Ø ===
–î–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ –≤–∫–ª—é—á–µ–Ω–æ –≥–ª—É–±–æ–∫–æ–µ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ. –¢—ã –î–û–õ–ñ–ï–ù:
1. –í—ã–ø–æ–ª–Ω–∏—Ç—å –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º—ã
2. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–ø—Ä–æ—Å —Å —Ä–∞–∑–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤
3. –û–±—ä—è—Å–Ω—è—Ç—å —Å–≤–æ–π reasoning –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ
4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–≤–æ–∏ –≤—ã–≤–æ–¥—ã –∏ –Ω–∞–π—Ç–∏ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
5. –î–∞—Ç—å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π, –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç

–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:
üìä **–ê–Ω–∞–ª–∏–∑ –≤–æ–ø—Ä–æ—Å–∞**: —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
üîç **–†–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –∞—Å–ø–µ–∫—Ç–æ–≤**: –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞
üí≠ **–†–∞–∑–º—ã—à–ª–µ–Ω–∏–µ**: –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
‚úÖ **–ó–∞–∫–ª—é—á–µ–Ω–∏–µ**: –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º
=== –ö–û–ù–ï–¶ –ò–ù–°–¢–†–£–ö–¶–ò–ò ===

"""
            enhanced_question = deep_think_instruction + enhanced_question
            logger.info(f"[Deep Think] Added deep thinking instructions to question")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ì–ê–†–ê–ù–¢ –µ—Å–ª–∏ –µ—Å—Ç—å
        if garant_context:
            enhanced_question = f"{enhanced_question}\n\n{garant_context}\n\n–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ì–ê–†–ê–ù–¢ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –¶–∏—Ç–∏—Ä—É–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –ì–ê–†–ê–ù–¢."
            logger.info(f"[ChatAgent] Added –ì–ê–†–ê–ù–¢ context to question")

        # –î–æ–±–∞–≤–ª—è–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –¥–µ–ª–∞
        if rag_context:
            enhanced_question = f"{enhanced_question}\n\n=== –ö–û–ù–¢–ï–ö–°–¢ –ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í –î–ï–õ–ê ===\n{rag_context}\n=== –ö–û–ù–ï–¶ –ö–û–ù–¢–ï–ö–°–¢–ê ===\n"
            logger.info("[ChatAgent] Added RAG context to question")
        
        if document_context or selected_text:
            context_parts = []
            if document_context:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ø–µ—Ä–≤—ã–µ 4000 —Å–∏–º–≤–æ–ª–æ–≤)
                doc_preview = document_context[:4000]
                context_parts.append(f"\n\n=== –¢–ï–ö–£–©–ò–ô –î–û–ö–£–ú–ï–ù–¢ –í –†–ï–î–ê–ö–¢–û–†–ï ===\n{doc_preview}")
                if len(document_context) > 4000:
                    context_parts.append(f"\n[–î–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–µ–∑–∞–Ω, –≤—Å–µ–≥–æ {len(document_context)} —Å–∏–º–≤–æ–ª–æ–≤]")
            if selected_text:
                context_parts.append(f"\n\n=== –í–´–î–ï–õ–ï–ù–ù–´–ô –¢–ï–ö–°–¢ ===\n{selected_text}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è —Ä–µ–∂–∏–º–∞ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞
            context_parts.append(f"\n\n=== –í–ê–ñ–ù–û: –†–ï–ñ–ò–ú –†–ï–î–ê–ö–¢–û–†–ê –î–û–ö–£–ú–ï–ù–¢–ê ===\n")
            context_parts.append(f"–¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –ø–æ–ø—Ä–æ—Å–∏—Ç—å —Ç–µ–±—è:\n")
            context_parts.append(f"- –ò–∑–º–µ–Ω–∏—Ç—å –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç\n")
            context_parts.append(f"- –£–ª—É—á—à–∏—Ç—å —Ç–µ–∫—Å—Ç\n")
            context_parts.append(f"- –ü–µ—Ä–µ–ø–∏—Å–∞—Ç—å —á–∞—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞\n")
            context_parts.append(f"- –î–æ–±–∞–≤–∏—Ç—å –∏–ª–∏ —É–¥–∞–ª–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n\n")
            context_parts.append(f"–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∏–∑–º–µ–Ω–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç, —Ç—ã –î–û–õ–ñ–ï–ù:\n")
            context_parts.append(f"1. –î–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–π\n")
            context_parts.append(f"2. –í –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞ –¥–æ–±–∞–≤–∏—Ç—å –±–ª–æ–∫ —Å HTML –∫–æ–¥–æ–º –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n")
            context_parts.append(f"```html\n<–ø–æ–ª–Ω—ã–π HTML –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏>\n```\n")
            context_parts.append(f"–í–ê–ñ–ù–û: HTML –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω—ã–º –∏ –≤–∞–ª–∏–¥–Ω—ã–º, –≤–∫–ª—é—á–∞—è –≤—Å–µ —Ç–µ–≥–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n")
            context_parts.append(f"–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–¥–µ–ª–∏–ª —Ç–µ–∫—Å—Ç, –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –∫ –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É.\n")
            context_parts.append(f"–¢—ã –∏–º–µ–µ—à—å –¥–æ—Å—Ç—É–ø –∫–æ –≤—Å–µ–º—É –¥–µ–ª—É (case_id={case_id}) –∏ –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–µ–ª–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n")
            
            enhanced_question = question + "".join(context_parts)
            logger.info(f"[ChatAgent] Enhanced question with document context (doc_len={len(document_context) if document_context else 0}, selected_len={len(selected_text) if selected_text else 0})")
        
        try:
            # Stream –æ—Ç–≤–µ—Ç –æ—Ç ChatAgent
            async for chunk in chat_agent.answer_stream(enhanced_question):
                if chunk:
                    full_response_text += chunk
                    yield f"data: {json.dumps({'textDelta': chunk}, ensure_ascii=False)}\n\n"
            
            # –ü—Ä–æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ì–ê–†–ê–ù–¢ –≤ –æ—Ç–≤–µ—Ç–µ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω legal_research)
            if legal_research and len(full_response_text) < 8000:
                try:
                    from app.services.external_sources.source_router import initialize_source_router
                    source_router = initialize_source_router(rag_service=rag_service, register_official_sources=True)
                    garant_source = source_router._sources.get("garant") if source_router else None
                    if garant_source:
                        logger.info(f"[ChatAgent] Attempting to insert Garant links (text length: {len(full_response_text)} chars)")
                        text_with_links = await garant_source.insert_links(full_response_text)
                        if text_with_links and text_with_links != full_response_text:
                            full_response_text = text_with_links
                            logger.info(f"[ChatAgent] Successfully inserted Garant links")
                except Exception as e:
                    logger.warning(f"[ChatAgent] Failed to insert Garant links: {e}", exc_info=True)
            
            # –î–ª—è —Ä–µ–∂–∏–º–∞ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: –∏–∑–≤–ª–µ–∫–∞–µ–º edited_content –∏–∑ –æ—Ç–≤–µ—Ç–∞
            if document_id and document_context:
                import re
                edited_content = None
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å HTML –∏–∑ code blocks
                html_match = re.search(r'```(?:html)?\s*\n(.*?)\n```', full_response_text, re.DOTALL)
                if html_match:
                    edited_content = html_match.group(1).strip()
                    logger.info(f"[ChatAgent] Extracted edited_content from code block (length: {len(edited_content)})")
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ HTML —Ç–µ–≥–∏ –≤ –æ—Ç–≤–µ—Ç–µ
                    html_tag_match = re.search(r'<[^>]+>.*?</[^>]+>', full_response_text, re.DOTALL)
                    if html_tag_match:
                        edited_content = html_tag_match.group(0)
                        logger.info(f"[ChatAgent] Extracted edited_content from HTML tags (length: {len(edited_content)})")
                
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ edited_content, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ —á–µ—Ä–µ–∑ SSE
                if edited_content:
                    yield f"data: {json.dumps({'type': 'edited_content', 'edited_content': edited_content}, ensure_ascii=False)}\n\n"
                    logger.info(f"[ChatAgent] Sent edited_content event (length: {len(edited_content)})")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –ë–î
            try:
                assistant_message_placeholder.content = full_response_text
                db.commit()
                logger.info(f"[ChatAgent] Response saved to DB")
            except Exception as save_error:
                db.rollback()
                logger.warning(f"[ChatAgent] Failed to save response: {save_error}")
            
            return
            
        except Exception as agent_error:
            logger.error(f"[ChatAgent] Error using ChatAgent: {agent_error}", exc_info=True)
            yield f"data: {json.dumps({'error': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. ChatAgent –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω.'})}\n\n"
            return
    
    except Exception as e:
        if assistant_message_id:
            try:
                assistant_message = db.query(ChatMessage).filter(
                    ChatMessage.id == assistant_message_id
                ).first()
                if assistant_message:
                    assistant_message.content = full_response_text
                    assistant_message.source_references = sources_list if sources_list else None
                    db.commit()
                    logger.info(f"Assistant message updated in DB for case {case_id}, id: {assistant_message_id}")
                else:
                    logger.warning(f"Assistant message placeholder {assistant_message_id} not found, creating new one")
                    # Fallback: —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –µ—Å–ª–∏ placeholder –Ω–µ –Ω–∞–π–¥–µ–Ω
                    assistant_message = ChatMessage(
                        case_id=case_id,
                        role="assistant",
                        content=full_response_text,
                        source_references=sources_list if sources_list else None,
                        session_id=session_id
                    )
                    db.add(assistant_message)
                    db.commit()
            except Exception as update_error:
                db.rollback()
                logger.error(f"Error updating assistant message in DB: {update_error}", exc_info=True)
                # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ fallback
                try:
                    assistant_message = ChatMessage(
                        case_id=case_id,
                        role="assistant",
                        content=full_response_text,
                        source_references=sources_list if sources_list else None,
                        session_id=session_id
                    )
                    db.add(assistant_message)
                    db.commit()
                    logger.info(f"Assistant message created as fallback for case {case_id}")
                except Exception as fallback_error:
                    db.rollback()
                    logger.error(f"Error creating fallback assistant message: {fallback_error}", exc_info=True)
        
        logger.error(f"Error in stream_chat_response: {e}", exc_info=True)
        yield f"data: {json.dumps({'error': str(e)})}\n\n"


@router.post("/api/assistant/chat")
async def assistant_chat(
    request: Request,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Streaming chat endpoint for assistant-ui
    
    Uses RAG only - simple question answering without agents.
    Accepts request body with messages array and case_id
    Returns Server-Sent Events (SSE) stream
    """
    try:
        # Parse request body
        body = await request.json()
        messages = body.get("messages", [])
        case_id = body.get("case_id") or body.get("caseId")
        web_search_raw = body.get("web_search", False)
        # Normalize web_search to boolean
        if isinstance(web_search_raw, str):
            web_search = web_search_raw.lower() in ("true", "1", "yes")
        else:
            web_search = bool(web_search_raw)
        legal_research_raw = body.get("legal_research", False)
        # Normalize legal_research to boolean
        if isinstance(legal_research_raw, str):
            legal_research = legal_research_raw.lower() in ("true", "1", "yes")
        else:
            legal_research = bool(legal_research_raw)
        deep_think = body.get("deep_think", False)
        draft_mode_raw = body.get("draft_mode", False)
        # Normalize draft_mode to boolean
        if isinstance(draft_mode_raw, str):
            draft_mode = draft_mode_raw.lower() in ("true", "1", "yes")
        else:
            draft_mode = bool(draft_mode_raw)
        
        # Document editor context (optional)
        document_context = body.get("document_context")
        document_id = body.get("document_id")
        selected_text = body.get("selected_text")
        
        # Template file ID for draft mode (optional) - –¥–ª—è —Ñ–∞–π–ª–æ–≤ –∏–∑ –ë–î
        template_file_id = body.get("template_file_id")
        # Template file content for draft mode (optional) - –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        template_file_content = body.get("template_file_content")
        
        # Attached file IDs for regular messages (optional) - –¥–ª—è —è–≤–Ω–æ–≥–æ —É–∫–∞–∑–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        attached_file_ids = body.get("attached_file_ids")
        if attached_file_ids:
            logger.info(f"Attached file IDs received: {attached_file_ids}")
        
        if not case_id:
            raise HTTPException(status_code=400, detail="case_id is required")
        
        # Get last user message
        if not messages:
            raise HTTPException(status_code=400, detail="No messages provided")
        
        last_message = messages[-1]
        if last_message.get("role") != "user":
            raise HTTPException(status_code=400, detail="Last message must be from user")
        
        question = last_message.get("content", "")
        
        # Use direct RAG stream_chat_response - no agents, simple question answering
        return StreamingResponse(
            stream_chat_response(
                case_id=case_id,
                question=question,
                db=db,
                current_user=current_user,
                background_tasks=background_tasks,
                web_search=web_search,
                legal_research=legal_research,
                deep_think=deep_think,
                draft_mode=draft_mode,
                document_context=document_context,
                document_id=document_id,
                selected_text=selected_text,
                template_file_id=template_file_id,
                template_file_content=template_file_content,
                attached_file_ids=attached_file_ids
            ),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in assistant_chat endpoint: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/assistant/chat/{case_id}/sessions")
async def get_chat_sessions_for_case(
    case_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Get list of chat sessions for a specific case
    
    Returns: list of sessions with session_id, first_message, last_message, last_message_at, message_count
    """
    # Check if case exists and verify ownership
    case = db.query(Case).filter(
        Case.id == case_id,
        Case.user_id == current_user.id
    ).first()
    if not case:
        raise HTTPException(status_code=404, detail="–î–µ–ª–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    try:
        from sqlalchemy import func, desc
        
        # Get all unique session_ids for this case
        sessions_query = db.query(
            ChatMessage.session_id,
            func.min(ChatMessage.created_at).label('first_message_at'),
            func.max(ChatMessage.created_at).label('last_message_at'),
            func.count(ChatMessage.id).label('message_count')
        ).filter(
            ChatMessage.case_id == case_id,
            ChatMessage.content.isnot(None),
            ChatMessage.content != "",
            ChatMessage.session_id.isnot(None)
        ).group_by(ChatMessage.session_id).order_by(desc('last_message_at')).all()
        
        sessions = []
        for session_row in sessions_query:
            session_id = session_row.session_id
            
            # Get first and last messages for preview
            first_message = db.query(ChatMessage).filter(
                ChatMessage.case_id == case_id,
                ChatMessage.session_id == session_id,
                ChatMessage.content.isnot(None),
                ChatMessage.content != ""
            ).order_by(ChatMessage.created_at.asc()).first()
            
            last_message = db.query(ChatMessage).filter(
                ChatMessage.case_id == case_id,
                ChatMessage.session_id == session_id,
                ChatMessage.content.isnot(None),
                ChatMessage.content != ""
            ).order_by(ChatMessage.created_at.desc()).first()
            
            first_message_preview = ""
            if first_message and first_message.content:
                first_message_preview = first_message.content[:100]
                if len(first_message.content) > 100:
                    first_message_preview += "..."
            
            last_message_preview = ""
            if last_message and last_message.content:
                last_message_preview = last_message.content[:100]
                if len(last_message.content) > 100:
                    last_message_preview += "..."
            
            sessions.append({
                "session_id": session_id,
                "first_message": first_message_preview,
                "last_message": last_message_preview,
                "first_message_at": first_message.created_at.isoformat() if first_message and first_message.created_at else None,
                "last_message_at": last_message.created_at.isoformat() if last_message and last_message.created_at else None,
                "message_count": session_row.message_count
            })
        
        return {"sessions": sessions}
    except Exception as e:
        logger.error(f"Error getting chat sessions for case {case_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to get chat sessions")


@router.get("/api/assistant/chat/{case_id}/history")
async def get_assistant_chat_history(
    case_id: str,
    session_id: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Get chat history for assistant chat
    
    Args:
        case_id: Case identifier
        session_id: Optional session ID to filter messages by session. If not provided, returns all messages for the case.
    
    Returns: list of messages with role, content, sources, created_at, session_id
    """
    # Check if case exists and verify ownership
    case = db.query(Case).filter(
        Case.id == case_id,
        Case.user_id == current_user.id
    ).first()
    if not case:
        raise HTTPException(status_code=404, detail="–î–µ–ª–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # Get messages - —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –ø–æ session_id –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    query = db.query(ChatMessage).filter(
        ChatMessage.case_id == case_id,
        ChatMessage.content.isnot(None),
        ChatMessage.content != ""
    )
    
    if session_id:
        query = query.filter(ChatMessage.session_id == session_id)
    
    messages = query.order_by(ChatMessage.created_at.asc()).all()
    
    return {
        "messages": [
            {
                "role": msg.role,
                "content": msg.content or "",
                "sources": msg.source_references if msg.source_references is not None else [],
                "created_at": msg.created_at.isoformat() if msg.created_at else datetime.utcnow().isoformat(),
                "session_id": msg.session_id
            }
            for msg in messages
        ]
    }


class HumanFeedbackResponseRequest(BaseModel):
    """Request model for submitting human feedback response"""
    request_id: str = Field(..., description="–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏")
    response: str = Field(..., description="–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    case_id: Optional[str] = Field(None, description="–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–µ–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏)")


@router.post("/api/assistant/chat/human-feedback")
async def submit_human_feedback(
    request: HumanFeedbackResponseRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Submit human feedback response for agent requests
    
    This endpoint receives user responses to agent feedback requests
    (e.g., approval requests, clarification questions, etc.)
    """
    try:
        from app.services.langchain_agents.human_feedback import get_feedback_service
        
        # Get feedback service
        feedback_service = get_feedback_service(db)
        
        # Submit response
        success = feedback_service.receive_response(
            request_id=request.request_id,
            response=request.response,
            run_id=None  # run_id can be extracted from state if needed
        )
        
        if not success:
            logger.warning(f"Failed to submit feedback response for request {request.request_id}: request not found or already answered")
            raise HTTPException(
                status_code=404,
                detail="–ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω"
            )
        
        # Log feedback submission
        if request.case_id:
            from app.services.langchain_agents.audit_logger import get_audit_logger
            audit_logger = get_audit_logger()
            audit_logger.log_human_feedback(
                request_id=request.request_id,
                question="",  # Question is stored in the request itself
                response=request.response,
                case_id=request.case_id,
                user_id=str(current_user.id),
                approved=None  # Can be determined from response if needed
            )
        
        logger.info(f"Human feedback response submitted successfully for request {request.request_id}")
        
        return {
            "status": "success",
            "request_id": request.request_id,
            "message": "–û—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error submitting human feedback response: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
        )


class ResumeGraphRequest(BaseModel):
    """Request model for resuming graph execution after interrupt"""
    thread_id: str = Field(..., description="Thread ID –¥–ª—è resume")
    case_id: str = Field(..., description="–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–µ–ª–∞")
    answer: dict = Field(..., description="–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, {'doc_types': ['contract'], 'columns_clarification': '...'})")


@router.post("/api/assistant/chat/resume")
async def resume_graph_execution(
    request: ResumeGraphRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    –í–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –ø–æ—Å–ª–µ interrupt
    
    –≠—Ç–æ—Ç endpoint –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –æ—Ç –∞–≥–µ–Ω—Ç–∞
    –∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ —á–µ—Ä–µ–∑ Command(resume=...)
    """
    try:
        from app.services.langchain_agents.coordinator import AgentCoordinator
        from app.services.rag_service import RAGService
        from app.services.document_processor import DocumentProcessor
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–µ–ª–æ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        case = db.query(Case).filter(
            Case.id == request.case_id,
            Case.user_id == current_user.id
        ).first()
        
        if not case:
            raise HTTPException(
                status_code=404,
                detail="–î–µ–ª–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            )
        
        # –°–æ–∑–¥–∞–µ–º coordinator –¥–ª—è resume
        rag_service = RAGService()
        document_processor = DocumentProcessor()
        coordinator = AgentCoordinator(db, rag_service, document_processor)
        
        # –°–æ–∑–¥–∞–µ–º step_callback –¥–ª—è streaming (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
        # –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
        def step_callback(event):
            logger.debug(f"[Resume] Stream event: {type(event)}")
        
        # –í—ã–∑—ã–≤–∞–µ–º resume
        result = coordinator.resume_after_interrupt(
            thread_id=request.thread_id,
            case_id=request.case_id,
            answer=request.answer,
            step_callback=step_callback
        )
        
        logger.info(f"Graph execution resumed successfully for thread {request.thread_id}")
        
        return {
            "status": "resumed",
            "thread_id": request.thread_id,
            "result": result
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error resuming graph execution: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}"
        )

